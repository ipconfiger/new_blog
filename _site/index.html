<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>压力很大同志的BLOG</title>
  <meta name="description" content="">
  <link rel="stylesheet" href="/css/main.css">
</head>

  <body>

    <div class="site-header">

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <i class="fa fa-navicon fa-lg"></i>
      </a>

      <div class="trigger">
          <a class="page-link" href="/"> Home</a>
        
          
          <a class="page-link" href="/about.html">关于压力</a>
          
        
      </div>
    </nav>


</div>

    <div class="page-content">
      <div class="wrapper">
        

    <div class="post">
        <h3><a href="/2016-08-26/true_lies.html">真实的谎言</a></h3>
      
        <div class="body">
            <p><img alt="" src="http://oaye9fj7h.bkt.clouddn.com/A10D589B-431D-4E23-9208-EAC6DC5796E3_20160826213033.jpeg" />
最近王宝强的家事很火爆啊.一个草根明星的婚变刺激了各路男屌丝,女屌丝,人妖屌丝的神经,十八路诸侯讨伐董卓的时候也没有这般热闹吧.不过马蓉的谎言和本文没有半毛钱关系.我今天想说说真实的谎言.没有谎言的人生是不真实而虚幻的,那样的人生并不存在,总而言之言而总之,哪怕是虚幻到圣人级别的人也没有办法避免一件事情,那就是骗人,就算是不骗别人,多半也会骗骗自己.
男女之间骗来骗去没有意思的,所以其实我想说得其实是跟大家更加息息相关的,当然也和台湾骗子还有卖保健酒的没有关系.既然人人难免撒谎,那么我们在什么时候最容易下意识的撒谎呢?其实很多时候我们下意识的会在对外表达的时候倾向于有利于自己的方向去偏向,或者是倾向于自己最喜欢或者最想要的方向.所以很多时候人们在面对医生的时候都会下意识的撒谎,并不是因为我们欺骗医生能对病情有好处,但是因为不同的心理原因,我们往往过份夸大或者会隐藏部分的病情.原因其实也无非就是期望病情并非有多严重,或者是过份担心病情而下意识的对事实作出了修改.所以其实我们对事实的描述往往都是不真实和客观的.
医者,望闻问切,会问善问是良医的必备技能,既然大多数病人在面对医生的时候都会撒谎,那么在谎言里找到真相对医生来说非常的重要.当然我不是医生,不过在给系统诊断错误,在面对客户的投诉的时候,我们要做的事情其实和医生也差不多,遇到bug的客户其实和病人没啥区别,往往为了让自己占到便宜往往也会夸大其辞,有时候甚至不惜撒谎(捏造事实, 是真撒谎, 无中生有那种).所以客户你不能不信他,也不能全信他,每报一个BUG就是一出新的罗生门.
其实我写的也有所偏好,你们千万别信.古人曰得好,信之者死,学之者生.</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2016-08-26/true_lies.html">2016-08-26 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2016-03-16/server-side-swift.html">用swift开发服务端应用</a></h3>
      
        <div class="body">
            <p>去年Swift开源的时候就打算试试用Swift来开发服务端了, 不过事情太多, 很多轮子也不具备, 大抵上需要自己重写很多东西, 但是人民的力量是强大的, 几个月过去后, 大批的轮子已经在路上了, 由于IBM的金大腿加入, Swift进入后端开发的进度明显的加快了.IBM的云计算服务已经支持Swift作为后端服务的开发语言, 并且推出了Swift的Web框架:<a href="https://github.com/IBM-Swift/Kitura">Kitura </a> . 不过经过两天试用后发现此货编译尤其麻烦, release编译至今没有通过过一次, 且debug模式下性能问题也很突出, 遂放弃之, 后来在全球著名的同性交友网站上找到另外一个star超高的框架:<a href="https://github.com/necolt/Swifton">Swifton</a></p>
<p>这个框架的名字很有意思</p>
<p><img alt="" src="http://ww1.sinaimg.cn/large/578b198bgw1f20xcpria0j20zi0l2afy.jpg" />
由于路由这些都是照搬Rails, 而且又没有ORM, 脚手架命令更是空话, 文档就更是因陋就简了, 所以如果swift比较熟练的话自己RTFC是比较好的选择.</p>
<h2>环境预备</h2>
<p>Swift的服务端环境现在而今眼目下的状况是比较局促的, 如果不差钱买个垃圾桶拿去托管, 也ok, 要是自己准备Linux环境的话也就只能Ubuntu了,幸亏这个还是比较主流的,不过好些项目都在Centos上, 😂😂😂😂😂😂
本地开发环境比较好解决, 多亏了IBM的金大腿, <a href="https://github.com/IBM-Swift/Kitura">Kitura </a>  的Reponsitory里有Docker的脚本和Vagrant的vagrantfile. 由于我在本地开发用的是Vagrant, 所以只需要copy这个file到项目目录下, 然后vagrant up, 经过漫长的等待(大概20分钟), Swift的本地调试环境就搭建好了. </p>
<h2>开始快乐的coding</h2>
<p>首先建立一个项目</p>
<pre><code>$~/project_path&gt;swift build --init 
Creating Package.swift
Creating .gitignore
Creating Sources/
Creating Sources/main.swift
Creating Tests/
</code></pre>
<p>然后加入Swifton的依赖, vim Package.swift, 加入依赖后就是下面这样子:</p>
<pre><code>dependencies: [
              .Package(url: "https://github.com/necolt/Swifton.git",     versions: Version(0,0,5)..&lt;Version(1,0,0)),
              .Package(url: "https://github.com/necolt/Curassow.git", versions: Version(0,4,0)..&lt;Version(1,0,0)),
         ]
</code></pre>
<p>去中Curassow是一个嵌入式的Http Server, 部署的时候用它来部署, 好处是在生产环境可以直接启动多个进程来提高性能.
之后用</p>
<pre><code>$~/project_path&gt;swift build
</code></pre>
<p>就开始下载依赖开始编译了. 不过世事无常, 这里编译必定是会出错的. 因为Swift  build在Dev版加入了Test功能, 然后有个bug, 会和很多自带了Test项目的Tests目录冲突, 编译的时候报找不到Tests目录下的资源. 所以这里需要手动删除两个项目下的Tests目录</p>
<pre><code>$~/project_path&gt;rm -rf ./Packages/PathKit-0.6.1/Tests
$~/project_path&gt;rm -rf ./Packages/Stencil-0.5.3/Tests
</code></pre>
<p>之后再运行编译就会直接通过了.
当然现在啥也干不了, 只能证明环境通顺了, 下面开始正式coding.</p>
<p>先创建一个Controller.</p>
<pre><code>$~/project_path&gt;touch ./Sources/HelloController.swift
</code></pre>
<p>写入如下内容:</p>
<pre><code>import Swifton

class HelloController:Controller{
    override init() {
        super.init()
        action("index") {request in
            return renderJSON(["hello": "world"])
        }
    }
}
</code></pre>
<p>然后在main.swift里这么写:</p>
<pre><code>import Swifton
import Curassow
let router = Router()
router.get("/", HelloController()["index"])
serve { router.respond($0) }
</code></pre>
<p>然后编译</p>
<pre><code>$~/project_path&gt;swift build
Compiling Swift Module 'test00' (2 sources)
Linking project_name
</code></pre>
<p>运行:</p>
<pre><code>$~/project_path&gt;.build/debug/project_name
[2016-03-18 12:34:23 +0800] [80691] [INFO] Listening at http://0.0.0.0:8000    (80691)
[2016-03-18 12:34:23 +0800] [80692] [INFO] Booting worker process with pid: 80692
</code></pre>
<p>这个时候在浏览器里打开 http://127.0.0.1:8000 </p>
<p>打不开</p>
<p>对的, 不看到这里的人是会掉坑里的, 我故意的.
因为在Kitura的vagrantfile里映射的端口是8090到8090, 所以8000在外边是访问不到的, 有两个方法可以解决, 一个是修改启动的方式, 用参数 --bind 0.0.0.0:8090. 或者直接修改vagrantfile里的端口映射部分, 多加个8000到8000的映射即可
然后用浏览器打开, 就会出现久违的 </p>
<pre><code>{"hello": "world"}
</code></pre>
<h2>总结一下</h2>
<p>大体上来说用Swift来开发服务端应用应该具备可以玩耍的能力了, 但是用在生产环境下现在还缺乏大量的轮子以及文档和实操经验.
通过对Swifton的代码研究发现, Swift的表达能力还是很强的, Swifton的代码相当的短小精悍. Curassow也是一个仿Gunicorn的Server, 纯Swift实现, 也非常的值得研究代码, 性能实测由于Mac本地并发数的限制没有探到头, 有空找两台Ubuntu的机器来实测一下Curassow</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2016-03-16/server-side-swift.html">2016-03-16 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-07-19/bananatoast.html">程序员快手营养早餐->香蕉吐司卷</a></h3>
      
        <div class="body">
            <p>古语有云人是铁饭是钢一顿不吃饿得慌，早餐更是三餐中最重要的一顿，一顿丰盛美味的早餐可以在一天开始的时候给人充满能量，更重要的是，高热量食品在这个时候是可以随便吃的，不管你是不是在减肥，对一个整天坐着不动的程序员来说，早餐更是非常的重要（不吃早餐是不对的，千万注意）。</p>
<p>今天我们要做的是一款材料易得，制作简单快捷，营养丰富热量充足的快手早餐，香蕉吐司卷。</p>
<p>下面是我们需要用到的材料和器具</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu846cl35hj208c069q3p.jpg" /></p>
<ol>
<li>菜板当作案板使用，是整个操作的平台</li>
<li>吐司片</li>
<li>小米蕉</li>
<li>鸡蛋</li>
<li>烧烤铝箔</li>
<li>保鲜膜</li>
<li>空气炸锅（烤箱）</li>
</ol>
<p>等等，那个乱入的扇子是怎么回事，其实本来这里需要的是寿司帘，但是我家里的因为常年不用已经划掉了，所以这里用随处可得的扇子代替，当然不能把材料直接放扇子上，所以请出了保鲜膜助阵。</p>
<p>空气炸锅不是必备的，只是家里没有烤箱用来代替烤箱使用的，如果你家里这两个都么有，那么去买个空气炸锅吧，几百元搞定，可烤可炸，真的是居家旅行杀人越货必备的神器。</p>
<p>接下来我们先要做一些准备工作，首先是给空气炸锅（烤箱）预热，温度200度，时间是五分钟</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu84f0xxbmj208c0b4aau.jpg" /></p>
<p>在等预热的五分钟我们就可以把其他的准备工作做完。首先撕一片铝箔做一个盒子，待会儿用来装食物用</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu84h60zjyj208c069dgl.jpg" /></p>
<p>然后调一个鸡蛋</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu84hin5stj208c0b43zg.jpg" /></p>
<p>下面是大杀器塑料扇子出场了，把扇子放案板上，然后撕一片保鲜膜放上面</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu84ii5t03j208c0b4jsi.jpg" /></p>
<p>然后放上一片吐司，再剥一根香蕉放在吐司上，之所以选小米蕉，就是看中这货跟吐司的长度差不多，正好一个一个不浪费</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu84k60d10j208c0693z5.jpg" /></p>
<p>然后用吐司把香蕉卷起来</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu84klph10j208c0693z6.jpg" /></p>
<p>再把扇子卷起来，用力压，跟用寿司帘是一样的，加上保鲜膜压其实和用寿司帘做寿司反卷的方式差不多</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu84m5rf93j208c069mxs.jpg" /></p>
<p>压实之后放在铝箔盒子里，浇上蛋液，翻滚，等蛋液渗透</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu84n7zw7sj208c069754.jpg" /></p>
<p>其实这里有个步骤我漏掉了，铝箔盒子底部要刷点油.....不然会粘住</p>
<p>这个时候差不多可以进炸锅（烤箱）了，预热时间有没有五分钟无所谓，上面的工作做完了就可以开箱放进去了。</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu84pnizxbj208c069q3j.jpg" /></p>
<p>放进去后继续加五分钟时间，然后就可以去洗脸刷牙了，总共只花了五分钟而已。</p>
<p>最后等待叮的一声就可以出炉了</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu84rks81zj208c0b4dh2.jpg" /></p>
<p>成品就是这样子，金黄油亮的外皮，但是其实整个过程完全没有放油。</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu84sj1793j208c0b4jsk.jpg" /></p>
<p>无视掉乱入的扇子吧</p>
<p>配上minipresso的一杯香浓咖啡，一顿早餐再无遗憾</p>
<p>最赞的一点是，做完后很好收拾，只需要把调蛋的那个碗洗干净就好了。</p>
<p>连着写了三天的吃吃喝喝千万不要以为我转型去做美食节目了，下期我继续回归技术话题，我们来继续讨论GPS的问题。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-07-19/bananatoast.html">2015-07-19 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-07-14/programmer-and-coffee.html">简单做一杯好咖啡之Minipresso</a></h3>
      
        <div class="body">
            <p>香浓的Espresso是意大利咖啡的灵魂，是咖啡精华最集中的体现。意浓咖啡口味醇厚，有宛若焦糖的奇感妙意。要自己做Espresso其实很简单，尤其是当你有了利器Minipresso之后。</p>
<p>此款神器价格小贵，不到400即可入手，有人说这个价添点就能买台15Pa的机器了，但是太笨重了，此物小巧轻便，而且绿色环保无须额外的能源即可工作。我们先来看开箱：</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu2jxkr5gjj208c0b4752.jpg" /></p>
<p>跟一个小保温杯差不多大的体积</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu2jyqdvngj208c0b40ts.jpg" /></p>
<p>拆开是这幅样儿：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu2jz6aydwj208c0b4aau.jpg" /></p>
<p>拿在手里这般大小</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu2jzw2qpjj208c0b4my1.jpg" /></p>
<p>拆开就是下面几个部件，分别套起来就是整个东西了：</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu2k2bf4pdj208c0b4q49.jpg" /></p>
<p>在家里的时候其实杯子比较多余，量刚好一个shot。</p>
<p>下面我们来做一杯看看好用不，首先，用量勺慢上一勺咖啡粉</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu2k4jbal7j208c0b4t9q.jpg" /></p>
<p>这次还是上次那包哥伦比亚，因为是为手冲打的颗粒有点粗，下次换过专门的Espresso的粉。</p>
<p>把粉盒倒置在量勺上：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu2k6ag6wwj208c0b4jsb.jpg" /></p>
<p>然后翻转过来，这样子粉就都到粉盒里啦</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu2k76hyshj208c0b40tl.jpg" /></p>
<p>现在把粉盒放入主体中：</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu2k7q1zxuj208c0b4jsd.jpg" /></p>
<p>这个时候把滤头盖上，拧紧：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu2k8yt9znj208c0b43zg.jpg" /></p>
<p>就是右手那个，如果拧紧了就是这样子：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu2k9hjmu7j208c0b4dgt.jpg" /></p>
<p>然后给水槽加入开水</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu2kbru83wj208c0b4dgp.jpg" /></p>
<p>差不多这么多就够了</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu2kcd7l10j208c0b4q3o.jpg" /></p>
<p>把刚才组装好的主体部分拧上去，最后合体完成：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1eu2kdi5lr3j208c0b4wfi.jpg" /></p>
<p>把圆形的东西扭一下弹出来，这个就是气泵</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1eu2ke7q3z1j208c0b4q3x.jpg" /></p>
<p>这次我用了上次配的玻璃杯没用本身配的，因为玻璃杯更容易看清楚结果。现在用力按气泵，差不多一秒一次的频率，太快了也不好。</p>
<p>差不多按5次后就开始出水了，一开始要排掉一些气体。</p>
<p>最后的结果：
<img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1eu2kglj8t3j208c0b4t9n.jpg" /></p>
<p>厚厚的一层漂亮的金黄色cream，闻起来也很香</p>
<p>换个角度看看</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1eu2khp4ztuj208c0b475b.jpg" /></p>
<p>这个时候各种花式都可以任你玩咯。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-07-14/programmer-and-coffee.html">2015-07-14 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-07-09/airpressor.html">程序员与咖啡：远离速溶用爱乐压做杯好咖啡</a></h3>
      
        <div class="body">
            <p>如果没有咖啡，世界上不会有这么多精妙的代码，我们的生活不会如此绚丽多彩。但是大多数屌丝公司都只能配备速溶咖啡，就算是滴滴香浓的麦斯韦尔，只要是二合一的也都是充斥这氢化植物油（咖啡伴侣），大量的反式脂肪酸会摧毁程序员并不怎么健康的身体。一杯香浓的现磨咖啡显然才是程序员的最佳伴侣，但是煮咖啡是一件麻烦的事情，手冲（挂耳滴滤）的太苦，法压的又需要专门磨粗颗粒，虹吸，摩卡壶都是需要一大堆家伙式的。</p>
<p>这个时候爱乐压横空出世，从此我们可以快速制作一杯不错的手冲（压）咖啡了。
<img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1etwpmdtzzpj20b40b50tm.jpg" /></p>
<p>这货现在京东淘宝均有销售，不放心淘宝的就去美亚买，价格在300以内。</p>
<p>下面用我的爱乐压给大家演示一下做一杯好咖啡其实是很简单的。
首先把主体组装出来，和一根大针管差不多（旁边是配的杯子）</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1etwkt9qnrhj20b40d10tr.jpg" /></p>
<p>然后准备好咖啡，我用的在星巴克买的中度烘焙的哥伦比亚，在凉了以后不会产生过量的酸味，在这个大热天做冰咖很巴适。</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1etwkvm4olbj20b40fy768.jpg" /></p>
<p>星巴克提供磨豆服务，按照咖啡机用的粗细磨就好了。</p>
<p>把咖啡粉倒进去，配了量勺的，一份一勺，大概和下图差不多：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1etwkzy911ij20b40f0dh0.jpg" /></p>
<p>然后注入热水，饮水机烧开的就行了，不用100度，最佳温度是80多度，一份注入一格，大概到下图的位置，然后搅拌一下：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1etwl490qdjj20b40d63zj.jpg" /></p>
<p>静静的放一会儿，趁这个时间去组装它的头部。</p>
<p>头部是由一个紧固件，一片滤纸和一张金属滤片组成的：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1etwl7fos1xj20b40etq4i.jpg" /></p>
<p>滤纸是可以重复使用多次的，图上的滤纸已经用过一次了，按照发明人的说法，有人反复用了20多次，但是买的时候送了很大一摞，所以我一般反复用2次。</p>
<p>装好了是下面这样子的：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1etwlacthilj20b40d2ab4.jpg" /></p>
<p>现在由我来组成头部......  额~， 是把这个套在那个大针管上：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1etwldpgqbbj20b40ea0tw.jpg" /></p>
<p>摇一摇，然后整个倒过来放到最早放边上的那个杯子上。然后，用力压</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1etwlfhhi3oj20b40frmyi.jpg" /></p>
<p>然后一份香浓的咖啡就诞生了：</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1etwlhwuw7jj20b40cdgmm.jpg" /></p>
<p>这样一份浓度比较高，如果习惯美式咖啡就1:1加水，不过我习惯加奶</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1etwlls5utnj20b40bmaaz.jpg" /></p>
<p>这样一杯咖啡，放在冰箱里冻一下，爽呆，如果你要喝热的，记得先给奶加热</p>
<p>清洗起来也是很简单的，先把头部拆下来：</p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1etwlpdil4rj20b409pdgn.jpg" /></p>
<p>水龙头冲一冲就好了，是的，滤纸也可以冲一冲，甩干放好就行了。</p>
<p>最后把针管一推，咖啡渣子就清理出来了，之后水龙头冲冲就好了</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1etwohy6squj20b40evta6.jpg" /></p>
<p>对烟民来说这个渣子是堆烟灰缸的好东西，我是不抽烟的，不过拿来填花盆也是不错的材料</p>
<p>最后说说成本，一包咖啡粉大概50 到90元不等，可以喝一周左右，加上鲜奶的价格，核算下来每一杯成本在10元到15元上下，和星巴克的价格比较起来还是很划算的，主要是健康。</p>
<p>祝用得开心</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-07-09/airpressor.html">2015-07-09 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-05-13/GPS.html">为什么GPS记录的数据不准确</a></h3>
      
        <div class="body">
            <p>现在张朝阳和冯唐都跑步了，紧跟着跑步的App也热起来了。好了，我们买了跑鞋，下载了App开始跑起来，我们觉得，</p>
<h3>跑完后记录的数据应该是这样子的：</h3>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1es3m51r59vj207s0dtq3y.jpg" /></p>
<h3>但是现实情况确是这样子的：</h3>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1es3m605z4zj207s0dt0ty.jpg" /></p>
<p>明明都是在同一条路径上绕圈，为什么GPS会这样子扭来扭去的呢。</p>
<p>要弄明白其中的原因，我们要从GPS的原理说起。</p>
<p>大体上来说，GPS定位的原理可以用下面的图片来说明：</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1es3m70hzk6j207s05g3yr.jpg" /></p>
<p>具体的原理可以参见：<a href="http://www.cnblogs.com/magicboy110/archive/2010/12/09/1901669.html">传送门</a> 上图也来自这篇Blog。</p>
<p>简单来说就是，手机接收到4颗卫星的位置信息和时间戳（代表了你的位置到卫星位置的距离），然后根据三点定位的原理，blablabla掐指一算，就知道你的位置（经纬度和海拔）了。</p>
<h3>那么GPS为什么会不准呢？</h3>
<p>结合上面的原理，我们可以知道，GPS是通过获知和4颗能收到信号的卫星之间的距离来计算位置的，那么如果电磁波在理想的真空中传播，这当然是很精确的。但是地球太危险了，有很多情况可能会影响到这四个距离参数。</p>
<p>比如：</p>
<h4>1.地球电离层波动</h4>
<p>地球的电离层会反射、折射电磁波，然后电离层又不是一个厚度和形状恒定的一个壳体，所以当地球气候抽风的时候，我们收到的卫星广播的信号就不是直接过来的，从而接收到的距离就会有偏差，这样计算出来的位置就会偏离我们实际所在的位置。</p>
<h4>2.高层建筑遮挡、反射信号</h4>
<p>这个情况的原理如下图：</p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1es3m81ahghj207s06v3yl.jpg" /></p>
<p>如图可知，右边的高楼挡住了卫星的信号，而左边的高楼将信号折射了，所以你得到的卫星的距离就远了那么一点点，所以呢，你计算出来的位置就不在你实际的位置上了，而是在左边的高楼的左边去了。</p>
<p>在城市里边，这是最常见的GPS漂移的原因，所以建议大家如果用GPS记录跑步的话，还是去空旷开阔的地方会比较准。</p>
<h4>3.累计误差造成里程变大，速度变快</h4>
<p>形象的来说可以用下图来表示：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1es3m9clyiuj207s05c74g.jpg" /></p>
<h3>那么问题来了，怎么样才可以让GPS记录更加的准确呢？</h3>
<h2>请听下回分解</h2>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-05-13/GPS.html">2015-05-13 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-04-07/bsbdqj-supervisor-subprocess.html">百撕不得骑姐系列之丢失的signal</a></h3>
      
        <div class="body">
            <p>过节的时候写了个小东西，主进程用multiprocess开了几个子进程来分发任务给子进程执行，完成后子进程report结果给主进程。为了在主进程死掉后把子进程也干掉，我监听了TERM的信号，然后在收到这个信号后去kill掉所有子进程。看起来ok啦，跑起来也还好，假设这个功能是放在 serv.py 里，python serv.py &amp; 把它放到后台去，再kill 掉，一切都很ok，但是如果用supervisord把这个管理起来的话就出了问题，主进程基本上就没收到TERM的信号.</p>
<pre><code>def receive_signal(signum, stack):
    import sys
    for process in worker_process:
        process.terminate()
    logging.info('child killed')
    sys.exit(0)

signal.signal(signal.SIGTERM, receive_signal)
</code></pre>
<p>supervisord的配置</p>
<pre><code>[program:XXX]
command=/usr/bin/python serv.py
directory=/var/code/
umask=022
startsecs=0
stopwaitsecs=0
redirect_stderr=true
stdout_logfile=/var/log/XXX.log
autorestart=true
</code></pre>
<p>跑起来的时候 tail -f /var/log/XXX.log,在你 supervisorctl stop XXX 之后，是看不到child killed打印出来的。</p>
<p>遍阅各种资料发现supervisor是通过向子进程发TERM信号来杀进程的。但是这么貌似没有发过这个信号呢？然后我看到 stopwaitsecs=0 这个参数，当初设置成0是为了更快的重启进程。仔细想想是不是因为这个地方杀太快了还没发信号就把进程干掉了呢？立即把参数改成了  stopwaitsecs=1，然后，就解决了。</p>
<p>这个问题差不多花了一部电影的时间来解决，刚开始的时候真是百撕不得骑姐啊。回过头来看看，supervisor应该是用类似kill -9的方式来确保进程最终被干掉，但是如果stopwaitsecs=0的时候就干脆绕开了发TERM的信号直接就kill -9了，还是百撕不得骑姐，有机会看看supervisord的代码来看看是不是和我猜测的一样了。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-04-07/bsbdqj-supervisor-subprocess.html">2015-04-07 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2015-04-02/simple-rough-print-with-pi.html">不要驱动，简单粗暴的用树莓派驱动USB打印机</a></h3>
      
        <div class="body">
            <p>网上很多文章都是再说如何用树莓派来做一个通用打印服务器，但是在很多应用场景下，配置CUPS什么的真的是自己zuo自己die的好途径，各类linux下的驱动配置起来令人吐血。而驱动各种热敏票据打印机，比如打胶带啊，二维码贴纸啊，小票之类的打印机因为根本找不到linux的驱动，要搞起来更是Mission Imposiable。所以本文的目的就是为了不用驱动直接用USB接口的各类热敏打印机。因为没有驱动，所以我们只能用简单粗暴的方式通过USB直接操作打印机了。下面来看看怎么搞：</p>
<p>首先，你得有一台打印机，淘宝有卖的，几十元到一两百，可以打热敏胶带，所以做个打印服务器标签的东西也不错的，其他用途可以自行开发。</p>
<p>先把打印机用usb线接到树莓派上，然后在树莓派执行 lsusb 命令，这个时候会列表连接上的所有usb设备，如下:</p>
<pre><code>Bus 005 Device 001: ID 0000:0000 
Bus 001 Device 001: ID 0000:0000 
Bus 004 Device 001: ID 0000:0000 
Bus 003 Device 001: ID 0000:0000 
Bus 002 Device 006: ID 15d9:0a37 
Bus 002 Device 001: ID 0000:0000
</code></pre>
<p>这个时候不知道谁是打印机呢！不过不要紧，你拔掉打印机的usb线后再执行一次，看缺谁，谁就是打印机了。</p>
<p>ID后冒号隔开的两个数字就是usb设备的 vendor ID和product Id了，记下来先，一会儿连接的时候有大用。</p>
<p>为了连接打印机，你需要安装python-usb这个库，用于直接通过usb接口来操作usb设备。本文的第一个坑就出在这里，因为pip库里的版本有一个bug的方式在后面的库会用到，所以必须用从github里最新的去除了bug的代码里安装才不会出问题。所以只能</p>
<pre><code>git clone https://github.com/walac/pyusb.git
cd pyusb
python setup.py install
</code></pre>
<p>用这样子的方式来安装才行。</p>
<p>安装好后我们就可以通过usb接口来操作打印机了，由于大多数打印机都支持EPSON的打印协议（很古老的协议了，所以到处都支持），所以我们可以安装一个叫python-escpos 的库来通过python-usb来用EPSON的协议操作打印机。</p>
<pre><code>sudo pip install python-escpos
</code></pre>
<p>但是此处还是有坑，因为这货的文档基本上和实际情况就是牛头不对马嘴。所以就别管这货的文档了。</p>
<pre><code>from escpos import *
pt = printer.Usb(0x0fe6, 0x811e, 0, out_ep=0x03)
</code></pre>
<p>此处要注意  out_ep 不能用默认值，默认的铁定打不了，但是这里的封装又有问题不能去自动获取，所以下面给一段自动获取 out_ep 的代码</p>
<pre><code>import usb.core
import usb.util
import sys

dev =  usb.core.find(idVendor= 0x5345, idProduct= 0x1234)

cfg = dev.get_active_configuration()
intf = cfg[(0,0)]
ep = usb.util.find_descriptor(
    intf,
    # match the first OUT endpoint
    custom_match = \
    lambda e: \
    usb.util.endpoint_direction(e.bEndpointAddress) == \
    usb.util.ENDPOINT_OUT
)
dev.reset()
</code></pre>
<p>我手头的打印机获取到的out_ep是0x03,所以我就写的这个值。
之后呢就可以愉快的打印了：</p>
<pre><code>from escpos import *
usb = printer.Usb(0x0fe6, 0x811e, 0, out_ep=0x03)

usb.text(u"终于可以愉快的打印啦\n\n\n\n\n\n\n\n".encode('gbk'))

usb.image(‘image path’)  #打印图片（黑白2值）

usb.qr(‘值’)   #打印二维码

usb.set(codepage=None, align=‘center’)  #设置页面居中

usb.cut()  #切纸

usb.close()  #关闭连接
</code></pre>
<p>祝玩得愉快。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2015-04-02/simple-rough-print-with-pi.html">2015-04-02 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-06-25/noblocking-coredata-in-multithread.html">通则不痛，远离阻塞-在多线程环境中使用CoreData，以及一个简单的封装</a></h3>
      
        <div class="body">
            <p>上回书说道，其实CoreData学起来也没有很复杂，我们其实增删改查都和别的ORM大同小异。但是世界总是很复杂的，一根筋的去考虑问题很容易卡到蛋，默认情况下我们的代码都在Main Thread中执行，数据库操作一旦量多了，频繁了，势必会阻塞住主线程的其他操作，俗话说，卡住了。</p>
<p>这个世界天然是多线程的，所以我们操作数据也必须多线程。CoreData对多线程的支持比较奇怪（按照一般的思路来说），CoreData的NSPersistentStoreCoordinator和NSManagedObjectContext对象都是不能跨线程使用的，NSManagedObject也不行，有人想加锁不就完了。No，作为一个处女座是不能忍受这么丑陋的解决方案的。其实NSManagedObjectContext已经对跨线程提供了内置的支持，只不过方式比较特殊，需要脑洞大开才行。</p>
<p>在创建NSManagedObject的时候有个构造器参数initWithConcurrencyType就是解决的关键所在，这个参数是一个枚举，有三个可选值：</p>
<ol>
<li>NSConfinementConcurrencyType  (或者不加参数，默认就是这个)</li>
<li>NSMainQueueConcurrencyType    (表示只会在主线程中执行)</li>
<li>NSPrivateQueueConcurrencyType (表示可以在子线程中执行)</li>
</ol>
<p>那么究竟应该怎么使用才能无阻塞无痛呢？</p>
<p>经过参考： http://www.cocoanetics.com/2012/07/multi-context-coredata/ 这篇文章，我们使用三层 NSManagedObjectContext 嵌套的方式。</p>
<p>NSManagedObjectContext是可以基于其他的 NSManagedObjectContext的，通过 setParentContext 方法，可以设置另外一个 NSManagedObjectContext 为自己的父级，这个时候子级可以访问父级下所有的对象，而且子级 NSManagedObjectContext 的内容变化后，如果执行save方法，会自动的 merge 到父级 NSManagedObjectContext 中，也就是子级save后，变动会同步到父级 NSManagedObjectContext。当然这个时候父级也必须再save一次，如果父级没有父级了，那么就会直接向NSPersistentStoreCoordinator中写入，如果有就会接着向再上一层的父级冒泡......</p>
<p>那么这里如同参考的文章一样，通过三个级别的 NSManagedObjectContext， 一个负责在background更新NSPersistentStoreCoordinator。一个用在主线程，主要执行插入，修改和删除操作，一些小的查询也可以在这里同步执行，如果有大的查询，就起一个新的 NSPrivateQueueConcurrencyType 类型的 NSManagedObjectContext，然后放在后台去执行查询，查询完成后将结果返回主线程。</p>
<p>NSManagedObjectContext在后台线程执行是通过 performBlock 方法来实现的，在传入的匿名block中执行的代码就是在子线程中了，比如</p>
<pre><code>[_bgObjectContext performBlock:^{
    __block NSError *inner_error = nil;
    [_bgObjectContext save:&amp;inner_error];
}];
</code></pre>
<p>那么如果是查询的话，因为 NSManagedObject 也不能跨线程访问，所以在block里获取到的NSManagedObject对象只能将objectid传到主线程，主线程再通过 objectWithID 恢复对象的方法，如下面的示例：</p>
<pre><code>+(void)one:(NSString*)predicate on:(ObjectResult)handler{
    NSManagedObjectContext *ctx = [[mmDAO instance] createPrivateObjectContext];
    [ctx performBlock:^{
        NSFetchRequest *fetchRequest = [self makeRequest:ctx predicate:predicate orderby:nil offset:0 limit:1];
        NSError* error = nil;
        NSArray* results = [ctx executeFetchRequest:fetchRequest error:&amp;error];
        if (error) {
            NSLog(@"error: %@", error);
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        if ([results count]&lt;1) {
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        NSManagedObjectID *objId = ((NSManagedObject*)results[0]).objectID;
        [[mmDAO instance].mainObjectContext performBlock:^{
            handler([[mmDAO instance].mainObjectContext objectWithID:objId], nil);
        }];
    }];
}
</code></pre>
<p>最后我们将上述的要点结合起来，解决方案就呼之欲出了。</p>
<p>首先我们还是需要一个抽象存储和数据操作的核心</p>
<p>mmDAO.h</p>
<pre><code>//
//  mmDAO.h
//  agent
//
//  Created by LiMing on 14-6-24.
//  Copyright (c) 2014年 Alexander. All rights reserved.
//

#import &lt;Foundation/Foundation.h&gt;

typedef void(^OperationResult)(NSError* error);

@interface mmDAO : NSObject
@property (readonly, strong, nonatomic) NSOperationQueue *queue;
@property (readonly ,strong, nonatomic) NSManagedObjectContext *bgObjectContext;
@property (readonly, strong, nonatomic) NSManagedObjectContext *mainObjectContext;

+(mmDAO*)instance;
-(void) setupEnvModel:(NSString *)model DbFile:(NSString*)filename;
- (NSManagedObjectContext *)createPrivateObjectContext;
-(NSError*)save:(OperationResult)handler;

@end
</code></pre>
<p>mmDAO.m</p>
<pre><code>//
//  mmDAO.m
//  agent
//
//  Created by LiMing on 14-6-24.
//  Copyright (c) 2014年 Alexander. All rights reserved.
//

#import "mmDAO.h"
#import "mmAppDelegate.h"

static mmDAO *onlyInstance;

@interface mmDAO ()
@property (nonatomic, copy)NSString *modelName;
@property (nonatomic, copy)NSString *dbFileName;
@end

@implementation mmDAO
+(mmDAO*)instance{
    static dispatch_once_t onceToken;
    dispatch_once(&amp;onceToken, ^{
        onlyInstance = [[mmDAO alloc] init];
    });
    return onlyInstance;
}

- (instancetype)init
{
    self = [super init];
    if (self) {
    }
    return self;
}

-(void) setupEnvModel:(NSString *)model DbFile:(NSString*)filename{
    _modelName = model;
    _dbFileName = filename;
    [self initCoreDataStack];
}

- (void)initCoreDataStack
{
    NSPersistentStoreCoordinator *coordinator = [self persistentStoreCoordinator];
    if (coordinator != nil) {
        _bgObjectContext = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSPrivateQueueConcurrencyType];
        [_bgObjectContext setPersistentStoreCoordinator:coordinator];

        _mainObjectContext = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSMainQueueConcurrencyType];
        [_mainObjectContext setParentContext:_bgObjectContext];
    }

}


- (NSManagedObjectContext *)createPrivateObjectContext
{
    NSManagedObjectContext *ctx = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSPrivateQueueConcurrencyType];
    [ctx setParentContext:_mainObjectContext];

    return ctx;
}


- (NSManagedObjectModel *)managedObjectModel
{
    NSManagedObjectModel *managedObjectModel;
    NSURL *modelURL = [[NSBundle mainBundle] URLForResource:_modelName withExtension:@"momd"];
    managedObjectModel = [[NSManagedObjectModel alloc] initWithContentsOfURL:modelURL];
    return managedObjectModel;
}

- (NSPersistentStoreCoordinator *)persistentStoreCoordinator
{
    NSPersistentStoreCoordinator *persistentStoreCoordinator = nil;
    NSURL *storeURL = [[self applicationDocumentsDirectory] URLByAppendingPathComponent:_dbFileName];

    NSError *error = nil;
    persistentStoreCoordinator = [[NSPersistentStoreCoordinator alloc] initWithManagedObjectModel:[self managedObjectModel]];
    if (![persistentStoreCoordinator addPersistentStoreWithType:NSSQLiteStoreType configuration:nil URL:storeURL options:nil error:&amp;error]) {
        NSLog(@"Unresolved error %@, %@", error, [error userInfo]);
        abort();
    }
    return persistentStoreCoordinator;
}

- (NSURL *)applicationDocumentsDirectory
{
    return [[[NSFileManager defaultManager] URLsForDirectory:NSDocumentDirectory inDomains:NSUserDomainMask] lastObject];
}


-(NSError*)save:(OperationResult)handler{
    NSError *error;
    if ([_mainObjectContext hasChanges]) {
        [_mainObjectContext save:&amp;error];
        [_bgObjectContext performBlock:^{
            __block NSError *inner_error = nil;
            [_bgObjectContext save:&amp;inner_error];
            if (handler){
                //handler(error);
                //这里需要返回主线程，不然在回调里操作界面会出错
                [_mainObjectContext performBlock:^{
                    handler(error);
                }];
            }
        }];
    }
    return error;
}


@end
</code></pre>
<p>然后我们扩展 NSManagedObject，把操作注入到类里，这样子有个好处是可以自动获取类名，然后就不用子级写字符串的类名了。</p>
<p>NSManagedObject+helper.h</p>
<pre><code>//
//  NSManagedObject+helper.h
//  agent
//
//  Created by LiMing on 14-6-24.
//  Copyright (c) 2014年 bangban. All rights reserved.
//

typedef void(^ListResult)(NSArray* result, NSError *error);
typedef void(^ObjectResult)(id result, NSError *error);

#import &lt;CoreData/CoreData.h&gt;
#import "mmDAO.h"


@interface NSManagedObject (helper)

+(id)createNew;

+(NSError*)save:(OperationResult)handler;

+(NSArray*)filter:(NSString *)predicate orderby:(NSArray *)orders offset:(int)offset limit:(int)limit;

+(void)filter:(NSString *)predicate orderby:(NSArray *)orders offset:(int)offset limit:(int)limit on:(ListResult)handler;

+(id)one:(NSString*)predicate;

+(void)one:(NSString*)predicate on:(ObjectResult)handler;

+(void)delobject:(id)object;
@end
</code></pre>
<p>NSManagedObject+helper.m</p>
<pre><code>//
//  NSManagedObject+helper.m
//  agent
//
//  Created by LiMing on 14-6-24.
//  Copyright (c) 2014年 bangban. All rights reserved.
//

#import "NSManagedObject+helper.h"

@implementation NSManagedObject (helper)
+(id)createNew{
    NSString *className = [NSString stringWithUTF8String:object_getClassName(self)];
    return [NSEntityDescription insertNewObjectForEntityForName:className inManagedObjectContext:[mmDAO instance].mainObjectContext];
}

+(NSError*)save:(OperationResult)handler{
    return [[mmDAO instance] save:handler];
}

+(NSArray*)filter:(NSString *)predicate orderby:(NSArray *)orders offset:(int)offset limit:(int)limit{

    NSManagedObjectContext *ctx = [mmDAO instance].mainObjectContext;
    NSFetchRequest *fetchRequest = [self makeRequest:ctx predicate:predicate orderby:orders offset:offset limit:limit];

    NSError* error = nil;
    NSArray* results = [ctx executeFetchRequest:fetchRequest error:&amp;error];
    if (error) {
        NSLog(@"error: %@", error);
        return @[];
    }
    return results;
}


+(NSFetchRequest*)makeRequest:(NSManagedObjectContext*)ctx predicate:(NSString*)predicate orderby:(NSArray*)orders offset:(int)offset limit:(int)limit{
    NSString *className = [NSString stringWithUTF8String:object_getClassName(self)];
    NSFetchRequest *fetchRequest = [[NSFetchRequest alloc] init];
    [fetchRequest setEntity:[NSEntityDescription entityForName:className inManagedObjectContext:ctx]];
    [fetchRequest setPredicate:[NSPredicate predicateWithFormat:predicate]];
    NSMutableArray *orderArray = [[NSMutableArray alloc] init];
    if (orders!=nil) {
        for (NSString *order in orders) {
            NSSortDescriptor *orderDesc = nil;
            if ([[order substringToIndex:1] isEqualToString:@"-"]) {
                orderDesc = [[NSSortDescriptor alloc] initWithKey:[order substringFromIndex:1]
                                                        ascending:NO];
            }else{
                orderDesc = [[NSSortDescriptor alloc] initWithKey:order
                                                        ascending:YES];
            }
        }
        [fetchRequest setSortDescriptors:orderArray];
    }
    if (offset&gt;0) {
        [fetchRequest setFetchOffset:offset];
    }
    if (limit&gt;0) {
        [fetchRequest setFetchLimit:limit];
    }
    return fetchRequest;
}

+(void)filter:(NSString *)predicate orderby:(NSArray *)orders offset:(int)offset limit:(int)limit on:(ListResult)handler{

    NSManagedObjectContext *ctx = [[mmDAO instance] createPrivateObjectContext];
    [ctx performBlock:^{
        NSFetchRequest *fetchRequest = [self makeRequest:ctx predicate:predicate orderby:orders offset:offset limit:limit];
        NSError* error = nil;
        NSArray* results = [ctx executeFetchRequest:fetchRequest error:&amp;error];
        if (error) {
            NSLog(@"error: %@", error);
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        if ([results count]&lt;1) {
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        NSMutableArray *result_ids = [[NSMutableArray alloc] init];
        for (NSManagedObject *item  in results) {
            NSLog(@"id=%@", item.objectID);
            [result_ids addObject:item.objectID];
        }
        [[mmDAO instance].mainObjectContext performBlock:^{
            NSMutableArray *final_results = [[NSMutableArray alloc] init];
            for (NSManagedObjectID *oid in result_ids) {
                [final_results addObject:[[mmDAO instance].mainObjectContext objectWithID:oid]];
            }
            handler(final_results, nil);
        }];
    }];
}


+(id)one:(NSString*)predicate{
    NSManagedObjectContext *ctx = [mmDAO instance].mainObjectContext;
    NSFetchRequest *fetchRequest = [self makeRequest:ctx predicate:predicate orderby:nil offset:0 limit:1];
    NSError* error = nil;
    NSArray* results = [ctx executeFetchRequest:fetchRequest error:&amp;error];
    if ([results count]!=1) {
        raise(1);
    }
    return results[0];
}

+(void)one:(NSString*)predicate on:(ObjectResult)handler{
    NSManagedObjectContext *ctx = [[mmDAO instance] createPrivateObjectContext];
    [ctx performBlock:^{
        NSFetchRequest *fetchRequest = [self makeRequest:ctx predicate:predicate orderby:nil offset:0 limit:1];
        NSError* error = nil;
        NSArray* results = [ctx executeFetchRequest:fetchRequest error:&amp;error];
        if (error) {
            NSLog(@"error: %@", error);
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        if ([results count]&lt;1) {
            [[mmDAO instance].mainObjectContext performBlock:^{
                handler(@[], nil);
            }];
        }
        NSManagedObjectID *objId = ((NSManagedObject*)results[0]).objectID;
        [[mmDAO instance].mainObjectContext performBlock:^{
            handler([[mmDAO instance].mainObjectContext objectWithID:objId], nil);
        }];
    }];
}


+(void)delobject:(id)object{
    //[[mmDAO instance].mainObjectContext delete:object];
    //这里方法名写错了
    [[mmDAO instance].mainObjectContext deleteObject:object];
}

@end
</code></pre>
<p>本文内容已经打包放在了github，有兴趣的可以fork下来直接用  <a href="https://github.com/ipconfiger/asyncCoreDataWrapper">https://github.com/ipconfiger/asyncCoreDataWrapper</a></p>
<p>另，文中代码有两处错误，已经加上了注释，提前看了的同学记得以github为准。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-06-25/noblocking-coredata-in-multithread.html">2014-06-25 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-06-25/coredata-guide-for-pythoner.html">给Python程序员的CoreData简单指南</a></h3>
      
        <div class="body">
            <p>刚上手的时候都说CoreData学习曲线很陡，其实如果有Hibernate或者SqlAlchemy经验的开发人员来说，只要相应的几个概念对上号了后，学习起来还是感觉挺简单的了。</p>
<blockquote>
<p>阅读本文需要Python编程经验，Objective－C编程经验以及使用SqlAlchemy的经验</p>
</blockquote>
<p>首先我们从概念上来理清楚一个对应关系</p>
<p>数据映射层：</p>
<table border="1">
    <tr>
        <td width="50%">SqlAlchemy</td>
        <td width="50%">CoreData</td>
    </tr>
    <tr>
        <td>
        SqlAlchemy的数据映射是由继承自sqlalchemy.ext.declarative下的declarative_base的类来定义的，我们必须手工指定字段的对应关系，写代码来完成映射的工作。
        </td>
        <td>
        CodeData的映射是由xcode维护的XML文件来定义，用工具可以生成对应的实体类文件，运行时通过NSManagedObjectModel的实例加载到程序里。
        </td>
    </tr>
</table>

<p>持久化层：</p>
<table border="1">
    <tr>
        <td width="50%">SqlAlchemy</td>
        <td width="50%">CoreData</td>
    </tr>
    <tr>
        <td width="50%">
        SqlAlchemy的持久化层是抽象了对数据库的连接和基本操作，比如：
        DB = create_engine(settings.DB_URI, encoding="utf-8", pool_recycle=settings.TIMEOUT, echo=False)
        所有的sql语句最终都是经过DB对象来执行的
        </td>
        <td width="50%">
        CodeData的持久话是通过NSPersistentStoreCoordinator类的实例来抽象的。如果就使用SqlLite底层持久话来看的化，等于是这个对象保持了对SqlLite的连接和通过他处理所有的SQL语句，事实上在构造的时候还传入了NSManagedObjectModel的实例，所以我猜生成SQL也是在这里完成的。
        </td>
    </tr>
</table>

<p>会话层：</p>
<p>会话层保持了对象状态，对对象的操作都是通过这个层级完成的。
<table border="1">
    <tr>
        <td width="50%">SqlAlchemy</td>
        <td width="50%">CoreData</td>
    </tr>
    <tr>
        <td>
        SqlAlchemy的会话层是通过一系列的session对象来实现的，最经常的数据操作都是通过这些session的对象来完成的。比如Session = scoped_session(sessionmaker(bind=DB))，然后  session ＝ Session()。最后得到的session对象就是会话层的对象了。
        </td>
        <td>
        CodeData的会话是通过NSManagedObjectContext类的实例来实现的会话，insert，delete，update和query都是通过会话来操作的。
        </td>
    </tr>
</table></p>
<blockquote>
<p>所以基本上ORM的大部分概念是想通的，我们了解了各自概念上相同的，可类比的地方，然后再搞清楚具体每个点上差异，那么基本上就可以很快的掌握新的技术了。</p>
</blockquote>
<p>下面从实际的代码上来感受一下相同点和不同点：</p>
<h2>Python Sqlalchemy版 初始化数据库环境：</h2>
<h3>model定义：</h3>
<pre><code>from sqlalchemy import Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base, declared_attr

TABLEARGS = {
    'mysql_engine': 'InnoDB',
    'mysql_charset': 'utf8'
}

class DeclaredBase(object):
    @declared_attr
    def __tablename__(cls):
        return cls.__name__.lower()
    id = Column(Integer, primary_key=True, autoincrement=True)

Base = declarative_base(cls=DeclaredBase)
GroupBase = declarative_base(cls=DeclaredBase)

class User(Base):
    user_id = Column(String(36), unique=True)
    user_name = Column(String(20))
    password = Column(String(36))
    gender = Column(Integer)
    online = Column(Boolean)
    last_update = Column(Integer)
    __table_args__ = TABLEARGS
</code></pre>
<h3>初始化持久话和会话：</h3>
<pre><code>from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session

DB = create_engine("localhost", encoding="utf-8", pool_recycle=3600, echo=False)
Session = scoped_session(sessionmaker(bind=DB))
db = Session()
</code></pre>
<h2>CoreData版 初始化数据库环境：</h2>
<h3>model定义</h3>
<p>值得开心的是，Xcode定义模型只需要点点鼠标填名字，太现代化了
<img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1ehqh5ifbwsj20bs0bhq3s.jpg" /></p>
<p>工具自动生成子类：</p>
<pre><code>#import &lt;Foundation/Foundation.h&gt;
#import &lt;CoreData/CoreData.h&gt;

@interface User : NSManagedObject

@property (nonatomic, retain) NSString * avatar;
@property (nonatomic, retain) NSDecimalNumber * balance;
@property (nonatomic, retain) NSString * birthday;
@property (nonatomic, retain) NSString * desp;
@property (nonatomic) int16_t gender;
@property (nonatomic, retain) NSString * mobile;
@property (nonatomic, retain) NSString * nick;
@property (nonatomic) int32_t user_id;

@end
</code></pre>
<h3>初始化持久话和会话：</h3>
<p>这一步顺序上和SqlAlchemy在顺序上有点区别，因为需要在持久话对象里传入数据模型对象，所以需要先实例化数据模型的对象</p>
<pre><code>//返回实例化后的模型对象
- (NSManagedObjectModel *)managedObjectModel
{
    NSManagedObjectModel *managedObjectModel;
    NSURL *modelURL = [[NSBundle mainBundle] URLForResource:@"模型的名字" withExtension:@"momd"];
    managedObjectModel = [[NSManagedObjectModel alloc] initWithContentsOfURL:modelURL];
    return managedObjectModel;
}

//返回实例化的持久话对象,对应到create_engine
- (NSPersistentStoreCoordinator *)persistentStoreCoordinator
{
    NSPersistentStoreCoordinator *persistentStoreCoordinator = nil;
    NSURL *storeURL = [[self applicationDocumentsDirectory] URLByAppendingPathComponent:@"agent.sqlite"];

    NSError *error = nil;
    persistentStoreCoordinator = [[NSPersistentStoreCoordinator alloc] initWithManagedObjectModel:[self managedObjectModel]];
    if (![persistentStoreCoordinator addPersistentStoreWithType:NSSQLiteStoreType configuration:nil URL:storeURL options:nil error:&amp;error]) {
        NSLog(@"Unresolved error %@, %@", error, [error userInfo]);
        abort();
    }
    return persistentStoreCoordinator;
}

   //返回会话对象，对应到 Session()
   - (NSManagedObjectContext *)createObjectContext:(NSPersistentStoreCoordinator*)coordinator
{
    NSManagedObjectContext *ctx = [[NSManagedObjectContext alloc] init];
    [ctx setPersistentStoreCoordinator:coordinator];
    return ctx;
}
</code></pre>
<p>相对来说Python的代码肯定短小很多了，Objective-C写起来比较啰嗦，但是其实简单的封装一下用起来也没有这么麻烦了。下回我们来说说封装的事情，这里就简单的丢到一个单例的类里就ok。Xcode的代码模版是把Coordinator和ObjectContext都放到了appDelegate对象里，但是必须</p>
<pre><code>[(YourAppDelegate*)[[UIApplication sharedApplication] delegate] doYourBusiness];
</code></pre>
<p>这样子才能访问，比较啰嗦，反正官方的例子都是放全局变量了，我们就用一个简单的单例代替：</p>
<pre><code>static mmDAO *onlyInstance;

@implementation mmDAO
+(mmDAO*)instance{
    static dispatch_once_t onceToken;
    dispatch_once(&amp;onceToken, ^{
        onlyInstance = [[mmDAO alloc] init];
    });
    return onlyInstance;
}

- (instancetype)init
{
    self = [super init];
    if (self) {
        [self initCoreDataStack];
    }
    return self;
}

- (void)initCoreDataStack
{
    NSPersistentStoreCoordinator *coordinator = [self persistentStoreCoordinator];
    if (coordinator != nil) {
        _ObjectContext = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSPrivateQueueConcurrencyType];
        [_ObjectContext setPersistentStoreCoordinator:coordinator];
    }

}

- (NSManagedObjectModel *)managedObjectModel
{
    NSManagedObjectModel *managedObjectModel;
    NSURL *modelURL = [[NSBundle mainBundle] URLForResource:@"XXX" withExtension:@"momd"];
    managedObjectModel = [[NSManagedObjectModel alloc] initWithContentsOfURL:modelURL];
    return managedObjectModel;
}

- (NSPersistentStoreCoordinator *)persistentStoreCoordinator
{
    NSPersistentStoreCoordinator *persistentStoreCoordinator = nil;
    NSURL *storeURL = [[self applicationDocumentsDirectory] URLByAppendingPathComponent:@"agent.sqlite"];

    NSError *error = nil;
    persistentStoreCoordinator = [[NSPersistentStoreCoordinator alloc] initWithManagedObjectModel:[self managedObjectModel]];
    if (![persistentStoreCoordinator addPersistentStoreWithType:NSSQLiteStoreType configuration:nil URL:storeURL options:nil error:&amp;error]) {
        NSLog(@"Unresolved error %@, %@", error, [error userInfo]);
        abort();
    }
    return persistentStoreCoordinator;
}

- (NSURL *)applicationDocumentsDirectory
{
    return [[[NSFileManager defaultManager] URLsForDirectory:NSDocumentDirectory inDomains:NSUserDomainMask] lastObject];
}

@end
</code></pre>
<p>这样子只需要通过</p>
<pre><code>[mmDAO instance].objectContext
</code></pre>
<p>就可以访问到会话对象来操作数据了</p>
<h2>各自版本的增删改</h2>
<p>SqlAlchemy的想法是创建一个对象，放入Context：</p>
<pre><code>user = User()
user.user_name = 'Alex'
...
session.add(user)
</code></pre>
<p>CoreData的想法是从Context里拿一个出来就不用放进去了：</p>
<pre><code>User *user = [NSEntityDescription insertNewObjectForEntityForName:@"User" inManagedObjectContext:[mmDAO instance].objectContext];
user.user_name = @"Alex"
...
</code></pre>
<p>SqlAlchemy删除对象的方法是，把对象丢进context的delete方法</p>
<pre><code>session.delete(user)
</code></pre>
<p>CoreData也是这样子</p>
<pre><code>[[mmDAO instance].objectContext delete:user];
</code></pre>
<p>SqlAlchemy插入了对象后，修改了对象的属性后，或者删除了对象后，只需要执行commit，就会将改动全部一次性提交给数据库，其实执行flush就可以，执行commit会提交事务。而CoreData也是通过Context的save方法将数据一次性提交给持久化设施，比如SqlLite。</p>
<blockquote>
<p>对比到这里其实我们可以发现，ORM的基本实现都趋同化了，在掌握一门ORM的操作后再学习其他的ORM其实也并不存在很抖的学习曲线。学过Hibernate的同学也可以通过相同的方式来类比一下，相信对于掌握CoreData的开发能够起到意想不到的作用</p>
</blockquote>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-06-25/coredata-guide-for-pythoner.html">2014-06-25 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-05-11/使NodeJs的require能够加载变更后的模块.html">使NodeJs的require能够加载变更后的模块</a></h3>
      
        <div class="body">
            <p>起因是这样子的，我打算做个工具，需要能够动态加载外部的模块，由于是跑起来需要比较长时间运行，所以需要能监测文件变更，一旦模块文件改动了就自动重新加载，网上流传的绝大部分心法都是监测文件变动后就重启一遍了事，这类天魔解体似的功法过于霸道，写起来麻烦，动辄涉及进程线程什么的大招，简便点的就是借助外物，比如node superviso之类的要全局安装的依赖，对于一个功能代码一百来行的小工具来说太过于霸道了，所以细查了node的文档后找到了一个比较简单的方法。</p>
<p>require模块有一个cache属性，动态加载的瓶颈就在这里，监测文件变更很easy，但是重复执行require模块得到的只能是第一次加载的内容，盖因为require模块把加载的外部模块都缓存在了cahce这个属性里。所以我们要作的事情就很简单了，cache是一个对象，我们只需要遍历这个对象的属性然后判断那些属性对应的模块变更过，就删掉这个属性，然后重新用require加载一边就ok了。</p>
<p>只是个小技巧，不用其他高深的功法，代码在 <a href="https://github.com/ipconfiger/node-mockit" title="node-mockit">传送阵：点击进入</a>
也就是前两天晚上写的小工具</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-05-11/使NodeJs的require能够加载变更后的模块.html">2014-05-11 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-05-06/最近啥都没写，赶脚好有负罪感.html">最近啥都没写，赶脚好有负罪感</a></h3>
      
        <div class="body">
            <p>RT</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-05-06/最近啥都没写，赶脚好有负罪感.html">2014-05-06 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-04-04/redis-message-with-tornado.html">用Redis作为后端来实现高性能的Longpolling消息系统</a></h3>
      
        <div class="body">
            <p>Redis是一个高性能的内存KV数据库，但是由于其支持了各种数据结构，所以我们还可以视其为一个高性能的数据结构，由此可以扩展出很多其他用途，比如用于实现一个可扩展的高性能消息系统。消息系统的前端可以用TCP也可以用HTTP来实现，TCP长连接在移动端受到很多限制，比如很多移动网关会自动关闭长时间空闲的TCP连接，所以还需要实现心跳，心跳频率也需要小心设计。而HTTP协议则是在互联网领域畅通无阻的协议，可以用在各种地方，但是HTTP是一个由客户端发起的无会话协议，轮询获取消息对服务端压力是很大的考验而且实时性也不是很好，要从服务端主动推送数据也是不可能的。但是Longpulling概念的推出解决了这个问题，服务器压力适中，实时性不输TCP长连接，在移动互联的时代也具备意义的事情是“长”轮询，正好规避了心跳包的问题，所以我们用Longpulling的http服务来作为消息服务的前端。</p>
<p>基本思路是这样子的。我们用tornado作为前端，手机App每两分钟发起一个http请求到tornado，请求会带一个客户端标识，比如user_id什么的，tornado收到这个ID后，对Redis发起一个blpop的请求，用这个ID作为key，这样子会阻塞这个请求直到超时，或者有一个值被push到这个key。</p>
<p>由于需要非阻塞的访问Redis，需要一个叫tornado-redis的库。</p>
<p>我们先 pip install tornado tornado-redis 安装需要的库</p>
<p>tornado的代码如下：</p>
<pre><code>from tornado import ioloop
from tornado import web
from tornado import gen
import tornadoredis
import logging
import settings

class MainHandler(web.RequestHandler):
    @web.asynchronous
    @gen.engine
    def get(self):
        tokens = self.get_argument("token").split(",")
        c = tornadoredis.Client(host=’127.0.0.1‘, port=6379, selected_db=1)
            message = yield gen.Task(c.blpop, tokens, 120)
        if message:
            self.finish(message.values()[0])
        else:
            self.finish("{}")

class SendHandler(web.RequestHandler):
    @web.asynchronous
    @gen.engine
    def post(self):
        to = self.get_argument("target")
        message = self.get_argument("message")
        c = tornadoredis.Client(host=’127.0.0.1‘, port=6379, selected_db=1)
            message = yield gen.Task(c.blpop, tokens, 120)
        rs = yield gen.Task(c.rpush, to, message)
        self.finish(json.dumps(dict(rs=True)))


application = web.Application([
    (r"/", MainHandler),
    (r"/send", SendHandler)
], debug=True)

if __name__ == "__main__":
    application.listen(int(sys.argv[1]))
    loop = ioloop.IOLoop.instance()
    loop.start()
</code></pre>
<p>上面的代码实现了一个基于redis的消息服务，支持消息持久化，支持点对点。</p>
<p>然后我们可以写一个IOS的App来测试这个broker：</p>
<p>核心Objective-C代码大致是下面这样子的：</p>
<pre><code>-(void) startListen:(void (^)(BOOL, NSString *))handler{
    NSMutableURLRequest* request = [NSMutableURLRequest requestWithURL:[NSURL URLWithString:self.url]];
    request.timeoutInterval = 120;
    if(queue==nil){
        queue = [[NSOperationQueue alloc] init];
    }
    NSLog(@"start listen");
    [NSURLConnection sendAsynchronousRequest:request queue:queue completionHandler:^(NSURLResponse *response, NSData *data, NSError *connectionError) {
    //
        if(connectionError){
            NSLog(@"%@",connectionError);
        }else{
            NSString* txt = [[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding];
            NSLog(@"%@",txt);
            handler(YES, txt);
        }
        [self startListen:handler];
    }];
}
</code></pre>
<p>如果觉得tornado的性能还不够的话还可以换node.js来。下面是一个参考的实现方式：</p>
<pre><code>var cluster = require('cluster');
var http = require('http');
var url = require('url');
var util = require('util');
var querystring = require('querystring');
var redis = require('redis')
var numCPUs = require('os').cpus().length;

function processResp(res, err, item){
    if(!err &amp;&amp; item){
        var data = JSON.parse(item[1]);
        res.end(JSON.stringify(data));
    }else{
        res.end(JSON.stringify(JSON.parse("{}")));
    }
}

function startServer(port){
    http.createServer(
        function (req, res) {        
            var arg = url.parse(req.url).query;
            var params = querystring.parse(arg);
            res.writeHead(200,{'Content-Type':'application/json'});
            var queue = params.token;
            var r = redis.createClient(6379, '127.0.0.1');
            r.blpop(queue, 10, function(err, item) {
                processResp(res, err, item);
            });
        }
    ).listen(port, "127.0.0.1");
}

if (cluster.isMaster){
    console.log('master stared');
    for (var i=0;i&lt;numCPUs;i++){
        cluster.fork();
    }
    cluster.on('listening', function(worker, address){
    });
}else if (cluster.isWorker){
    startServer(8888);
}
</code></pre>
<p>发送没写，需要的自己去实现。</p>
<p>扩展的方法：</p>
<p>用多组Redis组成多个区域，然后各自用一个域名来标识，比如 msg0到msg10，每个域一个redis实例，登录的时候给客户端分配一个区域就ok了。</p>
<p>如果想支持群组消息，就用pubsub来实现</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-04-04/redis-message-with-tornado.html">2014-04-04 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-01-16/dynamic-object-mapping-for-json.html">动态映射json数据到objective-c的对象</a></h3>
      
        <div class="body">
            <p>最近在实现IOS的app连接Restful Api的部分功能，发现从Api获取到json反序列化成字典后如果要映射到程序里的实体，需要写很多重复的代码，到处都是字符串，往往json结构比较复杂的时候会极其的蛋痛，所以实现了一个将字典对象映射到objective-c类实例属性的东东，顺便学习一下objective-c的一部分动态特性。</p>
<p>首先搭个架子先，因为要映射的目标很多，所以我们定义个基类，然后需要映射的类继承这个基类就ok了：</p>
<pre><code>@interface BaseModle : NSObject
- (id)init:(NSDictionary *)data;
@end
</code></pre>
<p>只需要暴露一个构造器就足够了，放入一个字典，然后一切基类自己搞定。</p>
<pre><code>#import "BaseModle.h"

@implementation BaseModle
-(id)init:(NSDictionary *)data{
    self = [super init];
    if (self){
        [self setAttributes:data];
    }
    return (self);
}

- (void)setAttributes:(NSDictionary *)data{
    //我们将在这里完成映射的功能，当然只是功能的起始点
}
@end
</code></pre>
<p>然后想一想，我们在子类里会定义很多属性，那么我们需要能够获取到这些属性的名称和类型。知道这些后再到字典里去取对应的键值赋值到属性上就ok啦。</p>
<p>要通过反射获取类里定义的属性列表，需要先引入 objc/message.h，这里定义了我们需要的class_copyPropertyList函数和objc_property_t类型。</p>
<pre><code>unsigned int outCount = 0;
objc_property_t *properties = class_copyPropertyList(self.class, &amp;outCount);
for (int i = 0; i &lt; outCount; i++) {
    objc_property_t property = properties[i];
    NSString *propName = [NSString stringWithUTF8String:property_getName(property)];
}
</code></pre>
<p>这个时候变量propName就是属性的名称了，这个时候只需要根据属性的名称从data里取对应的键值就ok了。得到值后需要给属性赋值，所以我们需要通过属性名称去构造一个给属性赋值的selector。</p>
<pre><code>- (SEL)getSetterAttributeName:(NSString *)attributeName
{
    NSString *capital = [[attributeName substringToIndex:1] uppercaseString];
    NSString *setterSelStr = [NSString stringWithFormat:@"set%@%@:",capital,[attributeName substringFromIndex:1]];
    return NSSelectorFromString(setterSelStr);
}
</code></pre>
<p>这个时候只需要 [self performSelectorOnMainThread:sel withObject:value waitUntilDone:YES]; 就可以给属性赋值了。</p>
<p>这个时候我们可以组织起第一个版本了，不过使用接口的一个喜欢呵呵的家伙说，如果json里有嵌套的字典怎么办呢？所以再进一步实现递归嵌套的功能。这个时候需要知道属性的类型，然后根据类型来动态创建一个新实例，然后把嵌套的字典丢进去继续映射。</p>
<p>先看看怎么获取属性的类型：</p>
<pre><code>- (NSDictionary *)attributeMapDictionary{
    NSMutableDictionary *propertyDict = [[NSMutableDictionary alloc] init];
    unsigned int outCount = 0;
    objc_property_t *properties = class_copyPropertyList(self.class, &amp;outCount);
    for (int i = 0; i &lt; outCount; i++) {
        objc_property_t property = properties[i];
        NSString *propName = [NSString stringWithUTF8String:property_getName(property)];
        const char *typeName =property_getAttributes(property);
        NSString *properyTypeName = [[NSString alloc] initWithCString:typeName encoding:NSUTF8StringEncoding];
        [propertyDict setObject:properyTypeName forKey:propName];
    }
    return propertyDict;
}
</code></pre>
<p>我们在刚才获取属性名的基础上扩展一下，现在我们获取到了属性的名称和类型名，然后生成一个用属性名为Key，属性类型名称作为Value的字典返回。</p>
<p>不过这个时候返回的类型名称是类似：T@"NSString",C,N,V_test 这样子蛋痛的形式，所以还需要一个解析函数来辅助</p>
<pre><code>- (NSString*) className:(NSString *)propertyTypeName {
    NSLog(@"%@", propertyTypeName);
    NSString* name = [[propertyTypeName componentsSeparatedByString:@","] objectAtIndex:0];
    NSString* cName = [[name substringToIndex:[name length]-1] substringFromIndex:3];
    return cName;
}
</code></pre>
<p>这个时侯我们可以得到一个干净的类名了，之后就可以通过NSClassFromString来获得类对象，然后实例化这个类型出来。整理一下第二个版本类似：</p>
<pre><code>- (void)setAttributes:(NSDictionary *)data{
    NSDictionary *propertys = [self attributeMapDictionary];
    for (NSString *attributeName in [propertys allKeys]){
        SEL sel = [self getSetterAttributeName:attributeName];
        if ([self respondsToSelector:sel]) {
            id value = [data objectForKey:attributeName];
            if (value) {
                NSString* className = [self className:[propertys objectForKey:attributeName]];
                if ([value isKindOfClass:[NSDictionary class]]) {
                    id subObject = [[NSClassFromString(className) alloc] init:value];
                    [self performSelectorOnMainThread:sel withObject: subObject waitUntilDone:YES];
                    continue;
                }                
                [self performSelectorOnMainThread:sel withObject:value waitUntilDone:YES];
            }
        }
    }
}
</code></pre>
<p>这个时候嵌套的类只需要定义属性为：</p>
<pre><code>@property (nonatomic, strong) MyClass *subObject;
</code></pre>
<p>但是再继续想一下，如果嵌套的是数组呢，数组里再有嵌套的字典呢，这个时候的麻烦是需要知道数组里的对象是什么类型，也就是在定义属性的时候要传入一个类型的名称进去。How？最后试了试，在定义protocal的时候获取到的名称会包含protocal的名称，比如定义一个空协议和要嵌套进去的类同名： </p>
<pre><code>@protocol MyClass
@end

@interface MyClass : BaseModle
@property (nonatomic, copy) NSString* test;
@property (nonatomic, strong) NSArray&lt;MyClass&gt;* subList;
@end
</code></pre>
<p>这个时候获取到的类型名称是：T@"NSArray<MyClass>",C,N,V_mySelf</p>
<p>这个时候修改一下获取类型名称的辅助方法就可以获取到嵌套的类型了。</p>
<p>完整的实现代码：</p>
<script src="https://gist.github.com/ipconfiger/8458066.js"></script>

<p>使用的话：</p>
<pre><code>#import "BaseModle.h"
@protocol mmMyObject
@end

@interface mmMyObject : BaseModle
@property (nonatomic, copy) NSString* test;
@property (nonatomic, copy) NSArray&lt;mmMyObject&gt;* mySelf;
@end
</code></pre>
<p>先定义一个子类，然后：</p>
<pre><code>mmMyObject *myobj = [[mmMyObject alloc] init:@{@"test": @"hahahaha", @"mySelf": @[@{@"test": @"huohuohuohuo"}]}];
mmMyObject *obj = [myobj.mySelf objectAtIndex:0];
NSLog(@"%@", obj.test);
</code></pre>
<p>得到结果：huohuohuohuo</p>
<h2>大功告成！！碎叫去也</h2>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-01-16/dynamic-object-mapping-for-json.html">2014-01-16 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2014-01-12/python-multitask-fixed.html">关于Python并行任务技巧的几点补完</a></h3>
      
        <div class="body">
            <p>早上逛微博发现了SegmentFault上的这篇文章：<a href="http://segmentfault.com/a/1190000000382873">关于Python并行任务技巧</a> 。看过之后大有裨益。顺手试了试后遇到几个小坑，记录下来作为补完（作者也有点语焉不详哦^_^）。</p>
<p>第一点是传入的function，只能接收一个传入参数，一开始以为在传入的序列里用tuple可以自动解包成多个参数传进去，可惜实践后是不行的：</p>
<pre><code>#coding=utf8
from multiprocessing import Pool

def do_add(n1, n2):
    return n1+n2

pool = Pool(5)
print pool.map(do_add, [(1,2),(3,4),(5,6)])
pool.close()
pool.join()
</code></pre>
<p>执行后结果就报错了：</p>
<pre><code>Traceback (most recent call last):
  File "mt.py", line 8, in &lt;module&gt;
    print pool.map(do_add, [(1,2),(3,4),(5,6)])
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py", line 250, in map
    return self.map_async(func, iterable, chunksize).get()
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py", line 554, in get
    raise self._value
TypeError: do_add() takes exactly 2 arguments (1 given)
</code></pre>
<p>第二是传入的function如果要做长期执行，比如放一个死循环在里面长期执行的话，必须处理必要的异常，不然ctrl+c杀不掉进程，比如：</p>
<pre><code>#coding=utf8
from multiprocessing import Pool
import time

def do_add(n1):
    while True:
        time.sleep(1)
        print n1

pool = Pool(5)
print pool.map(do_add, [1,2,3,4,5,6])
pool.close()
pool.join()
</code></pre>
<p>这段代码一跑起来是ctrl+c杀不掉的，最后只能把console整个关掉才行。
不过这么写就ok了：</p>
<pre><code>#coding=utf8
from multiprocessing import Pool
import time

def do_add(n1):
    try:
        while True:
            time.sleep(1)
            print n1
    except:
        return n1

pool = Pool(5)
print pool.map(do_add, [1,2,3,4,5,6])
pool.close()
pool.join()
</code></pre>
<hr />
<p>补完的补完，有网友提供了解决办法，使用functools的partial可以解决，详见 <a href="http://stackoverflow.com/questions/5442910/python-multiprocessing-pool-map-for-multiple-arguments">爆栈</a></p>
<hr />
<p>第三点是为什么要在子进程里用死循环让其长期执行。窃以为作者的直接把上千个任务暴力丢给进程池的做法并不是最高效的方式，即便是正在执行的进程数和CPU数能匹配得切到好处，但是一大堆的进程切换的开销也会有相当的负担。但是创建几个长期运行的工作进程，每个工作进程处理多个任务，省略掉了大量开启关闭进程的开销，原理上来说会效率高一些。不过这个问题我没有实测过。再不过其实从原理上来说这个开销虽然有但是并不是有多么大，很多时候完全可以忽略，比如作者用的例子。
所以其实更确切一点的需求反而是用于实现生产者消费者模式。因为在作者的例子里，任务数是固定的，不可控的，更多的时候我们反而是需要用生产者创建任务，由worker进程去执行任务。举个例子，生产者监听一个redis的队列，有新url放进去的时候就通知worker进程去取。</p>
<p>代码如下：</p>
<pre><code>#coding=utf8
from multiprocessing import Pool, Queue
import redis
import requests

queue = Queue(20)

def consumer():
    r = redis.Redis(host='127.0.0.1',port=6379,db=1)
    while True:
        k, url = r.blpop(['pool',])
        queue.put(url)

def worker():
    while True:
        url = queue.get()
        print requests.get(url).text

def process(ptype):
    try:
        if ptype:
            consumer()
        else:
            worker()
    except:
        pass

pool = Pool(5)
print pool.map(process, [1,0,0,0,0])
pool.close()
pool.join()
</code></pre>
<p>比起经典的方式来说简单很多，效率高，易懂，而且没什么死锁的陷阱。</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2014-01-12/python-multitask-fixed.html">2014-01-12 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2013-11-05/speedup-gunicorn-and-restart-gracefully.html">用meinheld加速gunicorn与优雅的重启gunicorn的worker</a></h3>
      
        <div class="body">
            <p>废话不用多说，异步的worker就是快，不要问为什么，gunicorn支持的多种worker，经过测试meinheld超级快，网上扒的测试结果，见图：
<img alt="image" src="http://www.360ito.com/misc/photo/13.jpg" />
没时间自己测了，有空的自己测试吧，下面用最简洁的步骤来实现用meinheld加速gunicorn。</p>
<p>step1:</p>
<pre><code>#pip install meinheld
</code></pre>
<p>step2:
修改supervisor的配置，添加</p>
<pre><code>--worker-class="egg:meinheld#gunicorn_worker”
</code></pre>
<p>这个参数。</p>
<p>重启，搞定</p>
<p>gunicorn还有一个问题是按照官网的文档用supervisor来管理后，一旦重启就会等很长时间来让mastor进程去boot子进程。官网文档还说了可以通过发送sighub给mastor进程可以“优雅”的重启子进程：<a href="http://docs.gunicorn.org/en/latest/signals.html">任意门</a></p>
<p>所以关键步骤就是发送SIGHUP信号给mastor进程就可以了。</p>
<pre><code>#!/bin/bash
if [ x$1 == x ]; then
   echo 'which app?'
   exit 1;
fi
pid=`ps -ef|grep $1|awk '{ print $3 }'|uniq -c|sort -k1,1nr|head -1|awk '{ print $2 }'`
rs=`kill -1 -$pid`
pc=`ps aux|grep $1|wc -l`
if [ $pc &gt; 1 ]; then
    echo 'restart done'
    exit 0;
else
    echo 'Error!Not start'
fi
</code></pre>
<p>保存为 restart.sh,chmod +x restart.sh  ,最后如果你的gunicorn是这样启动的：</p>
<pre><code>/usr/bin/gunicorn -w 8 -b 0.0.0.0:8000 --worker-class=egg:meinheld#gunicorn_worker app:app
</code></pre>
<p>就只需要   ./restart.sh app:app  就可以了</p>
<p>ps bash shell 不识别 -SIGHUP所以会报错 kill -l 找到对应的信号编号，换成 kill -1 就好了</p>
<p>祝玩得开心</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2013-11-05/speedup-gunicorn-and-restart-gracefully.html">2013-11-05 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2013-10-21/appletv3play.html">Apple TV3不完全试玩手册</a></h3>
      
        <div class="body">
            <h3>先来吐个槽</h3>
<p>入手Apple TV3是个很偶然的机会，之前一直想入手一个可以在电视上放网络电影的东西，所以试过很多不同奇葩的产品。最早是美如画的SD卡播放器，这货需要自己下载，传SD卡上，然后插电视，所以用起来非常不方便，所以用了没多久就束之高阁了。后来有个可以运行安卓系统的奇葩高清播放器，当时700多，片源很奇葩，操作很奇葩，说是安卓系统结果啥APP都装不了。最后折价处理掉了。后来出现了MK802这类安卓棒子，遂入了一个，便宜倒是便宜，不过需要外接一个无线鼠标，用起来响应速度还是不错，还能玩玩愤怒的小鸟，切切水果什么的，不过在沙发上用无线鼠标很是别扭。不过坏得也快，用了1个多月就坏掉了，一直停留在开机状态再也进不到系统了。之后有了树莓派，由于CPU很挫，所以XMBC跑起来相当的卡，而且XMBC又不能调用omxplayer去牛逼轰轰的玩硬解码1080p高清视频，因为omxplayer支持m3u8格式的HFS流播放方案，然后我就试图自己用百度网盘的API接口获取转码接口得到的m3u8文件通过omxplayer来播放。结果很容易出现音画不同步的情况。小米盒子，你抢得到么？抢到盒子的黄牛坐地起价要加400多，人争一口气佛争一炷香不买也罢。百度影棒？还会靠抢购的货，还只能用百度自家的片源。且各式各样的安卓盒子棒子什么的并不能良好的支持Airplay，所以干脆不看也不想，果断的Apple TV3了。</p>
<p>有空的时候会集其所有的盒子棒子做个横向对比，然后召唤神龙……
如果有好心人借我新小米盒子（抢不到），百度影棒（还是抢不到），阿里棒子（还没出)… 的话</p>
<h3>第一眼印象</h3>
<p>下面结束各种吐槽进入正题，我们来谈谈Apple TV3.（以下将用ATV3来表示）</p>
<p><img alt="image" src="http://www.techgradergeek.com/wp-content/uploads/2012/10/Apple-TV-3.png" /></p>
<p>先从外观入手，首先一个漂亮的外观是非常重要的，如果把ATV3和其他的盒子棒子放在一起就如同在停满大众的停车场里突然开进来一辆马萨拉蒂。有一个著名的理论就是如果看起来漂亮的飞机，一定是好飞机，窃以为同样的理论一样可以用于盒子界。如果都分不出精力来搞个漂亮的壳子，多半是因为连基本功能都还没调试妥当就拿出来销售了…</p>
<p>接口什么的就不用多说了，HDMI，网线（由于家里wifi不给力就插了跟网线，回头用Time Capsule来替换了），插上电源，把电视输入源切换到HDMI，然后哒哒~~~~</p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1e9tcf54y0tj20jz0dajtp.jpg" /></p>
<p>其实经过实测itunes上的影片是可以播放的，没有被墙，但是慢是慢得可以，你要是能等的话，还是能用，另经过测试里面的电台功能是可以用的，很流畅。操作上通过remote来控制非常的流畅，毫无违和感，由于手里没有小米盒子无法对比，以后有机会再来。</p>
<p>需要流畅度的看片，我们只能这么干：</p>
<h3>DNS劫持可以破</h3>
<p>DNS劫持这回事，其实是用一个DNS代理将ATV3的预告片频道的请求通过DNS代理层次劫持到指定的服务器上，服务器冒名顶替了预告片频道的内容，用搜狐，优酷，迅雷等片源的内容替代了预告片频道内部的内容。</p>
<p>新浪微博上的@盒子大师 提供了国内很多片源的DNS劫持服务</p>
<p>具体实施过程如下：
<img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1e9tcz12f6jj20ja0cr75r.jpg" /></p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1e9td6uaua4j20ji0bjq3q.jpg" /></p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1e9td8g3xa0j20jl0c1jsf.jpg" /></p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1e9td9xri7rj20jq0b2aay.jpg" /></p>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1e9tdbbm7n5j20jx0cpt9u.jpg" /></p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1e9tdedn2i8j20k30dujsq.jpg" /></p>
<p><img alt="image" src="http://ww2.sinaimg.cn/large/578b198bgw1e9tdfmzj3pj20je0bv3zk.jpg" /></p>
<p>设为这个值后一路点Remote，也就是遥控器上的Menu键回到首页，点击预告片：</p>
<p><img alt="image" src="http://ww4.sinaimg.cn/large/578b198bgw1e9tdhq1uusj20ju0eq76g.jpg" /></p>
<h3>世界将为你打开</h3>
<p><img alt="image" src="http://ww3.sinaimg.cn/large/578b198bgw1e9tdj34p8wj20kf0ecgob.jpg" /></p>
<p>去搜狐看看美剧：
<img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1e9tdknyvkqj20k10ecmyi.jpg" /></p>
<p><img alt="image" src="http://ww1.sinaimg.cn/large/578b198bgw1e9tdlytd8mj20k90djta9.jpg" /></p>
<p>Airplay就不上图了，上图也看不出区别，自家产品用起来超级简单，稳定。</p>
<p>很多安卓盒子、棒子都说自己支持Airplay，结果实际使用起来只能说是一塌糊涂，估计都是用了同一个开源项目的代码而已。xmbc的Airplay音频尚可，视频是连上一次断开后第二次死活搜索不到设备，也是完全不具备可用性。</p>
<p>大部分执着于安卓盒子或者树莓派的人最后给出的说法是要看移动硬盘下载下来的，这个随便一个硬盘盒子播放器就能搞定的事情，至于这么兴师动众么</p>
<h3>开发者的福利</h3>
<p>对于自己有开发能力的同学来说，@盒子大师 留下的个人链接的口是一个很方便的途径让ATV可以播放自己的片源，NAS的也好，或者百度网盘上的影片。</p>
<p>百度网盘是个不错的主意，很适合影片的分享，而且上面的片子都比较新，所以，我们来看看如何在ATV上播放网盘里的影片。</p>
<p>首先，如果想创建个人链接，你必须先注册DNS的帐号。在这个地方</p>
<p>密码用你想要注册的密码，因为登录不成功后就会让你再输入一次刚才的密码，然后就用你之前填的用户名密码注册了。</p>
<p>注册后在电脑上打开浏览器进入  http://www.atvttvv.net/  然后用刚才注册的用户名和密码登录。</p>
<p>先无视掉那个超级简陋的界面，据说@盒子大师 在做新版，也许到时候会完善界面功能什么的。这个时候我们可以去先准备播放的链接了。</p>
<p>由于用百度网盘的片源，我不打算用比较极端的hack的方式来获取播放地址，而是通过百度开放API的接口，其中有一个视频转码的接口很是销魂，可以指定清晰度转换输出对应的mp4格式的影片。经过实际调用发现，由于百度采用了分布式的转码技术，所以其实返回的是已经转码完成片段的m3u8文件。但是由于转码速度的问题仍需要大概好几分钟才能转码完毕，但是有不会通知你转码完毕了，所以只能不停的调用这个接口，直到最后获取的m3u8文件的大小不再变化为止。</p>
<h4>首先我们要登录百度帐号获取到token</h4>
<h1>注意，下面内容因为百度云的云转码接口不稳定，待稳定后再补上</h1>
        </div>
        
        <div class="meta">
            Posted on <a href="/2013-10-21/appletv3play.html">2013-10-21 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2013-08-08/torcast.html">基于Redis实现多个tornado进程间消息通信</a></h3>
      
        <div class="body">
            <p>说实话懒了很久没写过东西了，重头写起来主要是为了备忘</p>
<hr />
<p>tornado是一个在进程内单线程运行的web服务框架，虽然是单线程但是内部的IO都采用的非阻塞式的设计，所以跑起来速度是杠杠的。单进程空载的qps可以达到3500/s（官网数据）。但是好汉扛不过人多，所以大多数时候是需要多个进程一起工作来横向扩展处理能力，有得时候甚至需要多台服务器一起来，这个时候前端会有个反向代理来把所有的进程的请求管理起来，比如nginx，但是这个时候基于longpulling的一些应用就跑不起来了，比如tornado自带的那个chatroom的例子。Tornado自身没有实现http协议以外的异步IO，但是提供了IOStream可供我们来扩展，所以用IOStream和外部的消息分发的进程异步通信就能达到我们的目的，我这里使用Redis来实现消息分发。
redis是一个高性能的内存KV数据库，同时也具备简单高效的pubsub的能力，而且通信协议相当的简洁高效方便实现。redis的python client是阻塞的，所以这里我会用IOStream实现redis通信协议Publish和Subscribe这一部分。
首先来看IOStream，IOStream是对socket的异步封装，然后将socket事件注册到IOLoop中，这样由Tornado的事件主循环来控制socket的异步事件而不需要开启新的线程从而躲开GIL的墙。使用上IOStream很简单，把一个socket放进去就好了。</p>
<div class="highlight"><pre><span class="n">sock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span><span class="w"> </span><span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="n">stream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tornado</span><span class="o">.</span><span class="n">iostream</span><span class="o">.</span><span class="n">IOStream</span><span class="p">(</span><span class="n">sock</span><span class="p">)</span><span class="w"></span>
<span class="n">stream</span><span class="o">.</span><span class="n">connect</span><span class="p">((</span><span class="n">host</span><span class="p">,</span><span class="w"> </span><span class="n">port</span><span class="p">))</span><span class="w"></span>
</pre></div>

<p>这样子一个包装过的socket就可用了。
IOStream有几个非阻塞读的方法封装，包括</p>
<ol>
<li>read_until</li>
<li>read_bytes</li>
<li>read_until_close</li>
</ol>
<p>这三个方法都需要设定一个回调函数。read_until是设定一个间隔符号，直到读到这个间隔符号就执行回调函数。read_bytes是读取设定长度的byte，读满就执行回调函数。read_until_close是缓冲所有数据，直到链接关闭再执行回调函数。</p>
<p>IOStream的读写的方法都是非阻塞的，所以等待数据到达的方式是这样子的（以基于文本行的协议为例子）：</p>
<div class="highlight"><pre><span class="k">def</span><span class="w"> </span><span class="nf">recive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><span class="w"></span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">on_line</span><span class="p">(</span><span class="n">data</span><span class="p">):</span><span class="w"></span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">when_line</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span><span class="w"></span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">recive</span><span class="p">()</span><span class="w"></span>
<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="o">.</span><span class="n">read_until</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">on_line</span><span class="p">)</span><span class="w"></span>
</pre></div>

<p>由于Tornado的IOLoop一旦start起来就是个死循环，所以这些一定要放在在start执行前，在start之后的代码都没有执行的机会了。</p>
<p>然后就是用IOStream来实现Redis的通信协议了，不得不说这个协议真是简洁高效到可怕，如果不需要实现redis的所有命令的话其实我们只需要很少的代码就能实现。redis的通信协议参见 <a href="http://redis.io/topics/protocol">官方文档</a> <a href="http://redis.cn/topics/protocol.html">中文翻译版</a></p>
<p>通过协议规范可知其实简单的来看可以把redis的通信交互当成是基于文本行的协议来对待，当然如果想高效率的交互大量的数据还是可以用头+body的方式通过read_bytes来读取大量内容的部分。由于只花了一天来实现所有的功能包括demo，所以我直接用文本行的方式来处理，并且忽略了message以外的所有返回数据。</p>
<p>Redis数据库连接上了后需要select db，和subscribe这两个必要的操作才能开始等待消息到来，所以我们先封装Redis的命令。</p>
<div class="highlight"><pre><span class="k">def</span><span class="w"> </span><span class="nf">parseCommand</span><span class="p">(</span><span class="o">*</span><span class="n">argv</span><span class="p">):</span><span class="w"></span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[[</span><span class="s">&quot;*&quot;</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">argv</span><span class="p">)),</span><span class="s">&quot;</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">]]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">[[</span><span class="s">&quot;$&quot;</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span><span class="s">&quot;</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="s">&quot;</span><span class="se">\r\n</span><span class="s">&quot;</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="n">argv</span><span class="p">)]</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span><span class="w"> </span><span class="n">i1</span><span class="p">,</span><span class="n">i2</span><span class="p">:</span><span class="n">i1</span><span class="o">+</span><span class="n">i2</span><span class="w"> </span><span class="p">,</span><span class="n">output</span><span class="p">))</span><span class="w"></span>
</pre></div>

<p>由于redis的协议将命令和参数都一视同仁，所以处理起来是相当的简单，上面的3行代码基本上就可以输出所有的Redis命令了。</p>
<p>最后是解析redis的返回值了。根据redis的协议，多行返回是<em>开头，所以读取到 </em>就认为是有消息来了， *后面跟的是返回的条数，而每条都有一个标明自己长度的头，所以一共是条数x2这么多行，所以就获取完条数x2行后去掉$开头的行，剩下的就是数据了，第一个是类型，我们这里只需要获取message类型的，就放过其他数据，只需要遇到第一个值是message的执行回调函数返回频道名和消息本身就行了。</p>
<p>具体项目放在 <a href="https://github.com/ipconfiger/TorCast">https://github.com/ipconfiger/TorCast</a> 由于实现很仓促还是有很大的优化空间，暂时不建议在生产环境使用，其中Demo就是一个聊天室，类似tornado的demo，不过是可以在nginx做反向代理的多进程环境使用的。反正实现仓促代码混乱，如亮瞎氪金宝眼还请原谅则个。</p>
<p>另，我部署了一个demo在 <a href="http://42.121.19.100:8000">http://42.121.19.100:8000</a> 欢迎前来刷屏，看看多少人可以玩坏它</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2013-08-08/torcast.html">2013-08-08 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2011-12-11/mysql-schemaless.html">MySQL数据库支持Schemaless的数据库存储方案</a></h3>
      
        <div class="body">
            <p>在PyCon上有童鞋提供了一个类似概念的分享，不过不大适合一般类型的互联网项目，感觉有点过于另类。不过我实现这个方案是在看到PyCon的分享之前。算是同样的诉求不同的实现方式吧。且我这里只是实现了一个数据访问的组件而不是Server。</p>
<p>首先本文的方法来自FriendFeed分享的如何使用MySQL数据库的分享。简而言之就是把Python对象直接dumps后zip压缩存储在MySQL一个字段里。这样不就Schemaless了么？存什么数据类型，类什么结构，MySQL都不需要知道，加个属性什么的都不需要修改数据库表结构，对于业务快速变更、快速增长的互联网业务来说再合适不过了。访问对象直接通过主键查询，快速直接。but，查询怎么办？有的童鞋可能会问。OK，查询这事得分两说，如果是简单的检索，可以通过建索引表的方式来解决，或者呢用外部的索引，比如lucent，还能全文检索哦。现在而今眼目下我实现了索引表索引的方式，因为外部的索引方式比较千奇百怪，所以如果需要可以根据具体情况自己来写一个，反正实现相应的几个方法就行。</p>
<p>直接上一个例子来说明。假设要实现一个blog，需要存blog的信息，先定义一个blog的模型类(需要import什么大家自动脑补)</p>
<script src="https://gist.github.com/ipconfiger/6142119.js"></script>

<p>这个connection是因为我还没想好如何能无缝结合到Django中又能兼顾脱离Django独立使用的暂时措施，完成版会去掉</p>
<p>如果在使用django的话只需要 python manage.py shell 然后 Blog.objects.create_table()</p>
<p>这个时候会自动创建模型定义的表和索引表</p>
<script src="https://gist.github.com/ipconfiger/6142155.js"></script>

<p>这个时候，可以通过 Blog.objects.create(title=u"标题",content=u"内容",post_date=datetime.datetime.now(),auther=user) 或者Blog.objects.create(title=u"标题",content=u"内容",post_date=datetime.datetime.now(),auther=user.id)</p>
<p>就能够创建一个Blog的对象。这个时候blogs表和两个索引表都会插入数据。不过blogs表中的object列是人类无法理解的火星文..........</p>
<p>通过id直接获取对象  Blog.objects.get(1),根据索引获取  Blog.objects.auther.query(auther=user.id) 或者  Blog.objects.auther.query(auther=user)</p>
<p>这个会生成SQL，SELECT <code>id</code> FROM  <code>blog_idx_auther</code> WHERE <code>auther</code>=%s 然后取出match到对象的id列表，然后遍历id列表，通过 Blog.objects.get(id)获得的对象列表。</p>
<p>Blog.objects.get(id)的时候是有对象缓存的（现阶段通过redis实现），所以经过测试，速度是靠谱的。而相对MangoDB来说，MySQL的数据存储也更加靠谱一点，所以相比换现在而今眼目下还不怎么靠谱的mangodb来作为主存储来说，基于MySQL的Schemaless方案还是相对靠谱的。</p>
<p>项目地址：<a href="https://github.com/ipconfiger/free4my">https://github.com/ipconfiger/free4my</a> 内附demo的blog实现一枚</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2011-12-11/mysql-schemaless.html">2011-12-11 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2011-11-12/django-long-conn.html">让Django支持数据库长连接</a></h3>
      
        <div class="body">
            <p>书接上回 </p>
<p>上回我们说到：<a href="http://www.cnblogs.com/Alexander-Lee/archive/2011/05/02/tornado_host_django.html">《在生产系统使用Tornado WebServer来代替FastCGI加速你的Django应用》</a></p>
<p>那么现在很流行用一些高性能的nonblock的app server来host Django的应用，这些Server可以看做是一个单进程单线程的程序，然后用nginx在前端反向代理并且负载均衡到N多个后端工作进城来充分利用多CPU的性能，当然这部分的配置工作在上回已经说得很清楚了。但是对于Django来说有一个问题。因为Django的数据库连接是在查询的时候实时创建的，用完就会关掉，这样就会频繁的开闭连接。但是对于Tornado这种Server来说这种方式是低效的。这种Server最高效的工作模式是每个进程开启一个连接，并长期保持不关闭。本文的目的就是尝试使Django改变一贯的作风，采用这种高效的工作模式。本文基于Django1.3的版本，如果是低版本可以稍加更改一样可以使用。</p>
<p>Django的数据库可以通过配置使用专门定制的Backend，我们就从这里入手。</p>
<p>首先我们看看Django自带的Backend是如何实现的。在Django官网上可以看到自带MySql的Package结构，可以点击 此处 前往瞻仰。</p>
<p>通观源码我们可以发现，Django基本上是封装了MySQLdb的Connection和Cursor这两个对象。而且重头实现整个Backend既不实际而且也不能从根本上解决问题。所以我们可以换一个思路。所有的数据库操作都是从获取Connection对象开始的，而获取Connection对象只有一个入口，就是MySQLdb.connect这个函数。所以我们只需要包装MySQLdb这个模块，用我们自己的connect方法替代原本的，这样就从根源上解决了问题。我们在包装器内部维护MySQLdb的Connection对象，使其保持长连接，每次connect被调用的时候判断一下，如果连接存在就返回现有连接，不就完美了吗？所以我们可以分分钟写下第一个解决方案：</p>
<script src="https://gist.github.com/ipconfiger/6141949.js"></script>

<p>把上面代码存到一个叫pool.py的文件里。然后把Django源码里的db/backend/mysql这个package拷贝出来，单独存到我们project目录里一个mysql_pool的目录里。然后修改其中的base.py，在顶上import的部分，找到 import MySQLdb as Database 这句，用下面代码替换之</p>
<script src="https://gist.github.com/ipconfiger/6141966.js"></script>

<p>这样我们就用自己的模块替换了MySQLdb的，当要connect的时候判断到有连接的时候就不重新创建连接了。</p>
<p>把站点跑起来看，结果如何？刷新几次后报错了。Why？看看日志可以看到如下的错误：</p>
<script src="https://gist.github.com/ipconfiger/6142422.js"></script>

<p>看来我们光是包装了MySQLdb本身还不行，在connect后Django获取了Connection的对象，之后就能为所欲为，他用完后很自觉的关掉了，因为他直觉的以为每次connect都拿到了新的Connection对象。所以我们必须把Connection对象也包装了了。所以升级后的解决方案代码如下：</p>
<script src="https://gist.github.com/ipconfiger/6141996.js"></script>

<p>我们增加了一个_ConnectionWrapper类来代理Connection对象，然后屏蔽掉close函数。把站点跑起来后发现不会出现之前的问题了，跑起来也顺畅不少。但是过了几个小时后问题又来了。因为MySQLdb的Connection有个很蛋痛的问题，就是连接闲置8小时后会自己断掉。不过要解决这个问题很简单，我们发现连接如果闲置了快8小时就close掉重新建立一个连接不就行了么？所以最后解决方案的代码如下：
　
<script src="https://gist.github.com/ipconfiger/6142002.js"></script></p>
<p>就此问题解决，世界终于清净了</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2011-11-12/django-long-conn.html">2011-11-12 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2011-09-27/translate-tornado-template-document.html">翻译处女作欢迎批评指正－tornado的模板系统文档</a></h3>
      
        <div class="body">
            <p>jekyll的转义符太坑爹所以格式乱掉，还是看老地址吧<a href="http://www.cnblogs.com/Alexander-Lee/archive/2011/09/27/tornado_template.html">传送们</a> ，以前的Blog文章内嵌入了太多代码，搬迁困难</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2011-09-27/translate-tornado-template-document.html">2011-09-27 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2011-08-23/test.html">A Test Post</a></h3>
      
        <div class="body">
            <p>us imperdiet cursus mi congue. Cras ante augue, aliquam feugiat elementum quis, ullamcorper id lacus. Phasellus quis lectus nec elit pretium scelerisque. Aliquam leo felis, semper vel pellentesque id, tincidunt sed nisi. In lacus diam, faucibus ut euismod non, hendrerit quis sem. In quis massa vitae quam feugiat tempus. In eleifend tincidunt tellus a euismod. Aenean elementum, nisl sit amet fringilla lobortis, quam turpis consectetur urna, nec sollicitudin arcu justo vel magna.</p>
<p>Sed et lorem orci. Nullam consectetur elementum nibh, at aliquam metus adipiscing eget. Ut tincidunt fermentum urna, a eleifend dui volutpat eget. Integer varius nunc nec nulla tristique interdum. Suspendisse imperdiet libero sit amet lacus elementum nec dignissim dui accumsan. Curabitur at felis nunc, eu fermentum nisl. Curabitur quis ante non nisl hendrerit varius. Aliquam quis diam non massa gravida malesuada eu quis mi. Aenean tincidunt nunc vel sapien fermentum eu aliquam arcu tempor. Nulla risus</p>
<pre><code>def func():
    doc={"id":123}
    print doc
</code></pre>
        </div>
        
        <div class="meta">
            Posted on <a href="/2011-08-23/test.html">2011-08-23 00:00:00</a>
        </div>
    </div>

    <div class="post">
        <h3><a href="/2011-05-02/tornado-for-django.html">在生产系统使用Tornado WebServer来代替FastCGI加速你的Django应用</a></h3>
      
        <div class="body">
            <p>由于换了工作，所以之前的游戏引擎暂时放下，但是不会停止的，这个项目会在我的业余时间来完成。</p>
<p>---------------------------------------闷骚的分割线，下面是正文-------------------------------------------</p>
<p>tornado我在之前的文章里已经有过多次介绍，在此就不详细介绍了，</p>
<p>详细介绍可参见：</p>
<p><a href="http://www.cnblogs.com/Alexander-Lee/archive/2010/03/20/1690292.html">玩蛇记-使用tornado构建高性能Web应用之一</a> </p>
<p><a href="http://www.cnblogs.com/Alexander-Lee/archive/2010/03/24/1693367.html">玩蛇记-使用Tornado构建高性能Web之二-autoreload</a></p>
<p>由于官网被墙，讨论组也被墙（囧，万恶的墙）所以tornado的资料很少，官网的资料也语焉不详，所以很多童鞋对如何部署使用Tornado心里没底。所以本文的主要目的就是教会刚入门的新手如何在生产环境使用Tornado</p>
<p>Tornado是一个异步web框架和服务器，所以在开发longpulling的chat之类应用非常的合适，但是其实本身也是一个高性能的http服务器，也可以作为一个WSGIServer。所以即使你的网站没有使用Tornado的框架，而是用了web.py或者是Django来开发（傻瓜万岁），这个时候Tornado依然可以用来加速你的网站。使用Tornado来代替fastCGI可以大幅提高性能，且可以承载的并发能力也有了成倍的提高（大家可以自己Profile，本文只介绍如果做）。</p>
<p>下面我们开始来介绍如何配置。这里我们假设你的一个用Django写的网站在一台Linux的服务器上快乐地着（ubuntu or CentOS，没试过在其他发行版折腾过，windows？你在说笑吧），随着网站越来越红火，你越发感觉服务器不堪重负。这个时候Tornado出现了，他可以让你再苟延残喘好几个月，节约一大把的银子去把妹.............回到正题。根据官网的推荐部署方式，我们还是采用Nginx通过upstream来反向代理到N个Tornado的服务器实例上的部署方式。so</p>
<p>Setp1：安装supervisord</p>
<p>由于Tornado并没有自身提供Daemon的能力，所以我们需要用一个服务管理工具来管理Tornado的进程，supervisord是用Python实现的一款非常实用的进程管理工具。可以很方便的管理N过进程，且支持进程分组。Supervisord可以通过sudo easy_install supervisor安装，当然也可以通过Supervisord官网下载后setup.py install安装。</p>
<p>Step2: 给Django的站点增加一个Tornado的服务器文件（比如serv.py）</p>
<p>创建一个文件Serv.py在Django站点的根目录，内容如下：</p>
<script src="https://gist.github.com/ipconfiger/6142227.js"></script>

<p>我这里通过第一个参数来指定Tornado服务监听的端口。这样比较灵活，这点我们在后面的步骤会用到。这个时候我们可以通过</p>
<p>python Serv.py 8000</p>
<p>这个命令来启动服务器</p>
<p>Step3: 配置Supervisord</p>
<p>第一步安装的Supervisord还没有配置，所以我们需要先创建一个配置文件的样板。在root权限下执行</p>
<p>echo_supervisord_conf &gt; /etc/supervisord.conf</p>
<p>这个时候在/etc/创建了配置文件，用vim打开这个文件，在配置文件的屁股后面加上以下这一段</p>
<script src="https://gist.github.com/ipconfiger/6142234.js"></script>

<p>这个配置会启动4个Tornado的服务进程分别监听 8001,8002,8003,8004 这四个端口</p>
<p>command这一行是要执行的命令，这里是用 python /var/www/site/Serv.py 端口号来启动Tornado的服务进程 80%(process_num)02d 的用途是通过进程编号来生成端口号。下面的process_name这个参数也会用到。这里要指定的文件名就是上一步我们创建那个Serv.py文件</p>
<p>process_name是进程的名字，由于这里要启动4个进程，所以要用process_num来区分</p>
<p>umask是程序执行的权限参数</p>
<p>startsecs这个参数是程序启动的等待时间</p>
<p>stopwaitsecs这个参数是程序停止的等待时间</p>
<p>redirect_stderr这个参数将错误流重定向到std的流输出，这样可以省去一个日志文件的配置，当然也可以不用这个参数分开配置日志文件</p>
<p>stdout_logfile 这个参数是STD流输出日志文件的路径，Tornado会输出所有的请求和错误信息，通过这个可以统一做日志处理，分隔什么的，在程序里就只需要print到std流就行了。</p>
<p>numprocs 这个参数指定了进程的数量，这里是4，表明要启动4个Tornado进程</p>
<p>numprocs_start 这个参数指定了进程号的起始编号，这里是1，这样前面的command和process_name里的%(process_num)02d部分就会在执行的时候被替换为01~05的字符串</p>
<p>配置修改完成后:wq保存退出，执行：</p>
<p>supervisorctl reload</p>
<p>重新加载配置后，这些进程就启动起来了</p>
<p>Step4：修改配置Nginx</p>
<p>首先找到在vhost目录里你的站点配置文件，打开后，在头上增加upstream的内容</p>
<script src="https://gist.github.com/ipconfiger/6142241.js"></script>

<p>然后在Server配置节里找到</p>
<p>location 这个配置节</p>
<p>将内部清空，在其中加入upstream的配置，变成如下样子</p>
<script src="https://gist.github.com/ipconfiger/6142265.js"></script>

<p>保存配置文件后执行  让nginx重启的指令 nginx -s reload(注意 nginx文件在不同发行版中位置有差别)</p>
<p>然后你就能够通过域名看到你的网站了，试试是不是快多了</p>
<p>注意：生产系统下开启多少个Tornado进程比较好呢，这个见仁见智了，据我压力测试的结果看来，用CPU核数x2的数量最好，再多 就浪费了没有提升（为什么乘2？因为有种CPU上的技术叫超线程）。我的VPS上用的4个进程。如果是8核IntelCPU要挖尽CPU潜能的话需要开16个进程</p>
        </div>
        
        <div class="meta">
            Posted on <a href="/2011-05-02/tornado-for-django.html">2011-05-02 00:00:00</a>
        </div>
    </div>



      </div>
    </div>

    <div class="footer" align="center">

  Copyright &copy; <a href=http://diezcami.github.io target="_blank">Camille Diez</a> 2015<BR />
  Powered by <a href=http://jekyllrb.com target="_blank">Jekyll</a>

</div>

  </body>
</html>